<html>

<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta http-equiv="Content-Language" content="en-us">
<meta name="GENERATOR" content="Microsoft FrontPage 4.0">
<meta name="ProgId" content="FrontPage.Editor.Document">
<title>Collation Design Document</title>
<style>
<!--
body         { font-family: Times New Roman }
.primary     { background-color: #80FF80; text-align: Center; font-size: 80% }
.secondary   { background-color: #8080FF; text-align: Center; font-size: 80% }
.tertiary    { background-color: #FF8080; text-align: Center; font-size: 80% }
.case        { background-color: #80FFFF; text-align: Center; font-size: 80% }
.flag        { background-color: #FF0000; text-align: Center; font-size: 80% }
.q           { font-style: italic; font-weight: bold }
p            { font-family: Times New Roman }
li           { font-family: Times New Roman }
th           { background-color: #CCCCFF }
h2           { page-break-before: always }
-->
</style>
</head>

<body>

<h1 align="center">ICU Collation Design Documentation</h1>
<h3 align="center">Version #16d</h3>
<h3 align="center">2000-05-31</h3>
<h3 align="center"><i>Feedback: <a href="mailto:mark.davis@us.ibm.com">mailto:mark.davis@us.ibm.com</a></i></h3>
<h3 align="center">(<a href="ICU_collation_design.htm">Latest Version</a>)</h3>
<hr width="50%">
<h2 class="bb">Contents</h2>
<ol>
  <li><a href="#Introduction">Introduction</a>
    <ol>
      <li><a href="#Code_Links">Source Code Links</a></li>
    </ol>
  </li>
  <li><a href="#CollationElementFormat">Collation Elements</a>
    <ol>
      <li><a href="#Fractional_Collation_Elements">Fractional Collation Elements</a></li>
      <li><a href="#CollationElementFormat">Collation Element Format</a></li>
    </ol>
  </li>
  <li><a href="#Forming_Sort_Keys">Forming Sort Keys</a>
    <ol>
      <li><a href="#French">French</a></li>
      <li><a href="#Quarternary">Quarternary</a></li>
      <li><a href="#Case_Handling">Case Handling</a></li>
      <li><a href="#Compression">Compression</a></li>
      <li><a href="#Stack_Buffers">Stack Buffers</a></li>
      <li><a href="#Appending_Levels">Appending Levels</a></li>
      <li><a href="#Identical_Strength">Identical Strength</a></li>
    </ol>
  </li>
  <li><a href="#String_Compare">String Compare</a>
    <ol>
      <li><a href="#Backup">Backup</a></li>
    </ol>
  </li>
  <li><a href="#Data_Tables">Data Tables</a></li>
  <li><a href="#Fetching_CEs">Fetching CEs</a>
    <ol>
      <li><a href="#General">General</a>
        <ul>
          <li><a href="#Special_CEs">Special CEs</a></li>
          <li><a href="#Normalization">Normalization</a></li>
          <li><a href="#CheckFCD">CheckFCD</a></li>
          <li><a href="#GetSpecialCE">GetSpecialCE</a></li>
        </ul>
      </li>
      <li><a href="#Expansion_Table">Expansion Table</a></li>
      <li><a href="#Contraction Table">Contraction Table</a>
        <ul>
          <li><a href="#Discontiguous_Contractions">Discontiguous Contractions</a></li>
        </ul>
      </li>
      <li><a href="#Thai">Thai</a></li>
      <li><a href="#Surrogates">Surrogates</a></li>
      <li><a href="#Implicit_CEs">Implicit CEs</a>
        <ul>
          <li><a href="#Basic_CP">Basic CP</a></li>
          <li><a href="#Supplementary_CP">Supplementary CP</a></li>
          <li><a href="#UCA_Comparison">UCA Comparison</a></li>
          <li><a href="#Positioning_Implicit_CEs">Positioning Implicit CEs</a></li>
          <li><a href="#Hangul_Implicit_CEs">Hangul Implicit CEs</a></li>
        </ul>
      </li>
      <li><a href="#Charset_Ordering">Charset Ordering</a></li>
      <li><a href="#Script_Order">Script Order</a></li>
    </ol>
  </li>
  <li><a href="#Flat_File">Flat File</a>
    <ol>
      <li>
        <p align="left"><a href="#Postpone_Insertion">Postpone Insertion</a></li>
      <li>
        <p align="left"><a href="#Rule_Storage">Rule Storage</a></li>
      <li><a href="#Details_on_Generation">Details on Generation</a>
        <ul>
          <li><a href="#Tailoring_Structures">Tailoring Structures</a></li>
          <li><a href="#Building_Tokens">Building Tokens</a></li>
          <li>
            <p align="left"><a href="#Canonical_Closure">Canonical Closure</a></li>
          <li>
            <p align="left"><a href="#Add_Latin-1">Add Latin-1</a></li>
          <li><a href="#Assigning_CEs">Assigning CEs</a></li>
          <li>
            <p align="left"><a href="#Intermediate_CEs">Intermediate CEs</a></li>
          <li>
            <p align="left"><a href="#Assigning_Expansions">Assigning Expansions</a></li>
          <li>
            <p align="left"><a href="#Tailoring_Case_Bit">Tailoring Case Bit</a></li>
        </ul>
      </li>
    </ol>
  </li>
  <li><a href="#UCA_Processing">UCA Processing</a>
    <ol>
      <li><a href="#UCA_Case_Bit">UCA Case Bit</a></li>
    </ol>
  </li>
  <li><a href="#Rule_Syntax">Rule Syntax</a></li>
  <li><a href="#Versioning">Versioning</a>
    <ol>
      <li><a href="#Registration">Registration</a></li>
    </ol>
  </li>
  <li><a href="#API">API</a>
    <ol>
      <li><a href="#General_Attribute_API">General Attribute API</a></li>
      <li><a href="#Memory_API">Memory API</a></li>
      <li><a href="#Rule_Retrieval_API">Rule Retrieval API</a></li>
      <li><a href="#Custom_Data_API">Custom Data API</a></li>
      <li><a href="#Sort_Key_API">Sort Key API</a></li>
      <li><a href="#Script_Order_API">Script Order API</a></li>
      <li><a href="#Charset_Ordering_API">Charset Ordering API</a></li>
      <li><a href="#Loose_Match_Utility">Loose Match API</a></li>
      <li><a href="#Merge_Comparison_API">Merge Comparison API</a></li>
    </ol>
  </li>
  <li><a href="#Issues">Issues</a>
    <ol>
      <li><a href="#Parameterized_SHIFTED">Parameterized SHIFTED</a></li>
      <li><a href="#Indirect Positioning">Indirect Positioning</a></li>
      <li><a href="#Compressed_Primary_Weights">Compressed Primary Weights</a></li>
    </ol>
  </li>
</ol>
<ul>
  <li><a href="#Appendix_1">Appendix 1: Japanese Sort Order</a></li>
  <li><a href="#Appendix_2">Appendix 2: Compressing Primary Weights</a></li>
  <li><a href="#Appendix_3">Appendix 3: Data Files</a></li>
  <li><a href="#Requirements">Appendix 4: Requirements</a>
    <ol>
      <li><a href="#Performance">Performance</a></li>
    </ol>
  </li>
  <li><a href="#Magic_Bytes">Appendix 5: Magic Bytes</a></li>
  <li><a href="#Testing">Appendix 6: Testing</a></li>
  <li><a href="#Modifications">Modifications</a></li>
</ul>
<hr width="50%">
<h2>1 <a name="Introduction">Introduction</a></h2>
<p align="left">This document describes the proposed revisions to Collation in ICU. These revisions are for full UCA compliance, much better performance, much 
smaller sortkeys, faster initialization, smaller memory footprint, smaller disk footprint, additional parametric control, and additional tailoring control.
<p align="left">The techniques applied in this implementation are useful for a broader audience than simply collation. While Unicode is far, far more efficient 
than dealing with a multiplicity of separate code pages, the sheer size of the character set (from 0 to 10FFFF<sub>16</sub>) means that different types of 
algorithms and data structures are useful. The mechanisms used in collation can be useful in many other types of processing.</p>
<p align="left">However, collation itself does have many special characteristics. The goal is to have a uniform, fast mechanism for providing an ordering of 
strings that matches, to the extent possible, user perceptions of the &quot;correct&quot; order for their language. This involves features like multiple 
strength levels, contracting characters, and expanding characters, plus oddities such as French secondaries or Thai reordering. We will not dive into a 
discussion of these features; instead, readers must first read and be familiar with the following documents.</p>
<ul>
  <li>
    <p align="left"><i>Section 5.17 Sorting and Searching</i> from <i>The Unicode Standard</i></li>
  <li><a href="http://www.unicode.org/unicode/reports/tr10/">Unicode Technical Standard #10: Unicode Collation Algorithm</a> (UCA).
    <ul>
      <li>Examples from the current UCA table can be seen at <a href="http://www.unicode.org/unicode/reports/tr10/charts/Collation00.html">Collation Charts</a>.</li>
    </ul>
  </li>
</ul>
<p align="center"><b>&nbsp;<i>Without being familiar with these documents, the rest of this document will make little sense.</i></b></p>
<blockquote>
  <p align="left"><i><b>Note: </b>This is a working document, and often does not have the cleanest exposition. It has evolved with the development project, and 
  documents most heavily the parts that we found to be the trickiest. </i>See <a href="#Modifications">Modifications</a> for the latest document changes.</p>
</blockquote>
<h3>1.1 <a name="Code_Links">Source Code Links</a></h3>
<p>This document is liberally sprinkled with code fragments. These are meant to be illustrative, and will not necessarily track or match the final 
implementation, nor even necessarily be consistent with one another! The actual code can be found in the following list.</p>
<h4>API</h4>
<ul>
  <li><a href="http://oss.software.ibm.com/cvs/icu/icu/source/i18n/unicode/ucol.h">ucol.h</a> (C collator), <a
    href="http://oss.software.ibm.com/cvs/icu/icu/source/i18n/unicode/coll.h">coll.h</a>, <a
    href="http://oss.software.ibm.com/cvs/icu/icu/source/i18n/unicode/tblcoll.h">tblcoll.h</a> (C++ version)</li>
  <li><a href="http://oss.software.ibm.com/cvs/icu/icu/source/i18n/unicode/ucoleitr.h">ucoleitr.h</a>&nbsp; (C collation element iterator), <a
    href="http://oss.software.ibm.com/cvs/icu/icu/source/i18n/unicode/coleitr.h">coleitr.h</a> (C++ version)</li>
</ul>
<h4>Internals</h4>
<ul>
  <li><a href="http://oss.software.ibm.com/cvs/icu/icu/source/i18n/ucol.cpp">ucol.cpp</a>, <a
    href="http://oss.software.ibm.com/cvs/icu/icu/source/i18n/ucol_imp.h">ucol_imp.h</a> (main runtime implementation)</li>
  <li><a href="http://oss.software.ibm.com/cvs/icu/icu/source/i18n/ucol_bld.cpp">ucol_bld.cpp</a>, <a
    href="http://oss.software.ibm.com/cvs/icu/icu/source/i18n/ucol_bld.h">ucol_bld.h</a> (coordinates building of rule-based collator from rules)</li>
  <li><a href="http://oss.software.ibm.com/cvs/icu/icu/source/i18n/ucol_cnt.cpp">ucol_cnt.cpp</a>, <a
    href="http://oss.software.ibm.com/cvs/icu/icu/source/i18n/ucol_cnt.h">ucol_cnt.h</a> (handles building of contraction table)</li>
  <li><a href="http://oss.software.ibm.com/cvs/icu/icu/source/i18n/ucol_elm.cpp">ucol_elm.cpp</a>, <a
    href="http://oss.software.ibm.com/cvs/icu/icu/source/i18n/ucol_elm.h">ucol_elm.h</a> (handles all other building: flat table, expansions, etc.)</li>
  <li><a href="http://oss.software.ibm.com/cvs/icu/icu/source/i18n/ucol_tok.c">ucol_tok.c</a>, <a
    href="http://oss.software.ibm.com/cvs/icu/icu/source/i18n/ucol_tok.h">ucol_tok.h</a> (takes rules string and produces list of tokens)</li>
  <li><a href="http://oss.software.ibm.com/cvs/icu/icu/source/i18n/ucol_wgt.c">ucol_wgt.c</a>, <a
    href="http://oss.software.ibm.com/cvs/icu/icu/source/i18n/ucol_wgt.h">ucol_wgt.h</a> (generates CEs for tailoring)</li>
  <li><a href="http://oss.software.ibm.com/cvs/icu/icu/source/i18n/ucoleitr.cpp">ucoleitr.cpp</a> (collation element iterator)</li>
  <li><a href="http://oss.software.ibm.com/cvs/icu/icu/source/i18n/coll.cpp">coll.cpp</a>, <a
    href="http://oss.software.ibm.com/cvs/icu/icu/source/i18n/coleitr.cpp">coleitr.cpp</a>, <a
    href="http://oss.software.ibm.com/cvs/icu/icu/source/i18n/tblcoll.cpp">tblcoll.cpp</a> (C++ wrappers)</li>
</ul>
<h2 align="left">2 <a name="Collation_Elements">Collation Elements</a></h2>
<p align="left">The fundamental data element used in collation is the collation element (CE). The basic algorithm for sort keys is to fetch a collation element 
for each character, then extract different level fields from the CE, route those level fields to different weight lists, then concatenate the weight lists 
together. This is described much more detail in <a href="http://www.unicode.org/unicode/reports/tr10/">UTS #10: Unicode Collation Algorithm</a> in some detail, 
and we won't repeat that discussion here.</p>
<p align="left">ICU uses a type of collation element that differs somewhat from what is in UCA. It is called a <i>fractional collation element</i>, and 
described below. Although it differs in format from the integral collation element used in UCA, it can be used to produce the same results, but with the 
advantages of smaller sort-key size.</p>
<h3 align="left">2.1 <a name="Fractional_Collation_Elements"><b>Fractional Collation Elements</b></a></h3>
<p align="left">The following section was written originally in FAQ form. It has not been restructured yet to fit in with the format of the rest of the 
document.</p>
<p class="q" align="left">Q: A collation weight in the UCA is defined to be a 16 bit value (aka wyde). This will surely fail when Unicode 3.1 rolls around, with 
over 90,000 characters!</p>
<p class="a" align="left">A: The UCA makes provision for more than 64K weight values: see <a
href="http://www.unicode.org/unicode/reports/tr10/#Large Weight Values">Section 6.2 Large Weight Values</a> and also <a
href="http://www.unicode.org/unicode/reports/tr10/#Escape hatch">6.3.2 Escape Hatch</a>. This mechanism is also used in Weight Derivation, as in <a
href="http://www.unicode.org/unicode/reports/tr10/#LegalCodePoints">7.1.2 Legal code points</a>. It discusses using a sequence of two collation elements, of the 
form:</p>
<blockquote>
  <div align="left">
    <pre>[(X1+1).0000.0000], [yyyy.zzzz.wwww]</pre>
  </div>
</blockquote>
<p class="q" align="left">Q: I find this hard to follow. Is there any other way to explain the issue?</p>
<p class="a" align="left">Ok. We can look at the weights in a different way, which may help to clarify what is going on.</p>
<p class="a" align="left">We'll define <i>fractional collation elements</i> to be the same as standard collation elements except that each weight is a fraction 
between zero and one (instead of being an integer from 1 to FFFF). For ease in working with computers, these are binary fractions, represented as hexadecimal.</p>
<p class="a" align="left"><i>Examples:</i></p>
<ul>
  <li>
    <p class="a" align="left"><code>[0.000000000, 0.920000000, 0.02057A900]</code></li>
  <li>
    <p class="a" align="left"><code>[0.100000000, 0.A30000000, 0.02057A900]</code></li>
  <li>
    <p class="a" align="left"><code>[0.1202C456B, 0.78AF00000, 0.023A90000]</code></li>
</ul>
<p class="a" align="left">With fractional collation elements, it is easy to see that all Unicode code points (including the supplementary code points) could 
have distinct primary mappings: there are innumerably many more than 10FFFF possible fractions!</p>
<p class="q" align="left">Q: Is that all there is to it?</p>
<p class="a" align="left">Not quite. We still will have to turn these fractional collation elements into well-formed standard collation elements that we can use 
to build a sort key. To do that, we put some restrictions on the allowable values for the fractional weights. By adopting these restrictions, we make the 
conversion very simple, without limiting the indefinitely large range offered by fractional weights.</p>
<p class="a" align="left">Consider a fractional weight as broken into a sequence of bytes of 2 hex digits each, excluding any trailing bytes that would be 
entirely zero, and omitting the leading &quot;0.&quot;. (We could give a precise numeric definition, but it is easier to think of it as simply taking bytes at a 
time.)</p>
<p class="a" align="left"><i>Example:</i></p>
<blockquote>
  <p class="a" align="left"><b>0.12C456A000000...</b> breaks into four bytes: <b>12 C4 56 A0<br>
  0.12C456A320000....</b> breaks into five bytes: <b>12 C4</b> <b>56 A3</b>&nbsp; <b>20</b></p>
</blockquote>
<p class="a" align="left">So the first example of fractional collation elements becomes:</p>
<p class="a" align="left"><i>Examples:</i></p>
<ul>
  <li>
    <p class="a" align="left"><code>[,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 92,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
    02 05 7A 90]</code></li>
  <li>
    <p class="a" align="left"><code>[10,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; A3,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
    02 05 7A 90]</code></li>
  <li>
    <p class="a" align="left"><code>[12 02 C4 56 B0,&nbsp;&nbsp; 78 AF,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 02 3A 90]</code></li>
</ul>
<p class="a" align="left">Since we eventually will be showing that we could convert these fractional collation weights into standard ones, we will put some 
restrictions on the values taken by these fractions, based (not surprisingly) on their bytes. Since we have wide latitude in choosing the precise values for the 
fractional weights in setting up a collation table, these restrictions are not at all onerous.</p>
<p class="a" align="left"><b>R1. </b>No byte can be <b>00</b>,&nbsp; <b>01</b>, or <b>02</b>.</p>
<blockquote>
  <p class="a" align="left">The reason for this rule is to avoid collision with the <i>level separator</i> and with<i> null bytes </i>when the fractional weight 
  is eventually used in a sort key. The 02 is also used for <a href="#Merge_Comparison_API">Merge Comparison.</a></p>
</blockquote>
<p class="a" align="left"><i>Example:</i></p>
<blockquote>
  <p class="a" align="left"><b>12 C4 00 50</b> violates R1, since the third byte is zero.</p>
</blockquote>
<p class="a" align="left"><b>R2. </b>A fractional weight cannot exactly match the initial bytes of another fractional weight at the same level.</p>
<blockquote>
  <p class="a" align="left">The reason for this rule is to avoid having sort keys where the starting bytes from one string are compared against the trailing 
  bytes from another.</p>
</blockquote>
<p class="a" align="left"><i>Example:</i></p>
<blockquote>
  <p class="a" align="left">The two primary weights <b>A3 92 12 C4 50</b> and <b>A3 92 12 C4</b> violate R2. If the second weight were <b>A3 92 12 C5</b> or <b>A3 
  92 12 C4 52</b>, it would not violate R2.</p>
  <p class="a" align="left">Allowing fractions to break this rule would cause a problem when these bytes are pushed into a sort key (see next question). Let's 
  take an example where we just concentrate on the primary weights. Suppose x[1] = <b>A3</b>,&nbsp; y[1] = <b>A3 23</b>, and a[1] = <b>49</b>. Then we would get 
  the following ordering:</p>
  <table border="1">
    <tr>
      <td width="50%">a</td>
      <td width="50%">[<b>49 01...</b>]</td>
    </tr>
    <tr>
      <td width="50%">x</td>
      <td width="50%">[<b>A3 01...</b>]</td>
    </tr>
    <tr>
      <td width="50%">y</td>
      <td width="50%">[<b>A3 23 01 ...</b>]</td>
    </tr>
    <tr>
      <td width="50%">xa</td>
      <td width="50%">[<b>A3 49 01...</b>]</td>
    </tr>
  </table>
  <p class="a" align="left">Because the primary weights turn into different lengths, and they don't follow <b>R2</b>, we get incorrect behavior. If <b>R2</b> is 
  followed, this can never happen, since &quot;x&quot; and &quot;y&quot; would have to differ at some point <i>before</i> we ran out of bytes on one side.</p>
</blockquote>
<p class="a" align="left"><b>R3. </b>No fractional collation element can have a zero weight at Level N and a non-zero weight at Level N-1. Any collation 
elements that violate this rule are called <i>ill-formed</i>.</p>
<blockquote>
  <p class="a" align="left">The reason for this rule is to avoid allowing character to transpose, and still have the same sort key (cf.&nbsp; <a href="#Step 4">UCA 
  ยง4.4, Step 4: Compare</a>).</p>
</blockquote>
<p class="a" align="left">Any fractional collation element that does not meet these restrictions is called <i>ill-formed</i>.</p>
<p class="q" align="left">Q: Once I have a well-formed fractional collation element table, how do I generate a sort key?</p>
<p class="a" align="left">A fractional collation element table can easily be transformed into a standard one. Each fractional collation element is transformed 
into a sequence of one <i>or more</i> standard collation elements:</p>
<ul>
  <li>
    <p class="a" align="left">Break each fractional weight into a sequence of bytes.</li>
  <li>
    <p class="a" align="left">Take two bytes from each level to form a collation element.
    <ul>
      <li>
        <p class="a" align="left">If there is an odd number of bytes, use <b>02</b> for the second byte.</li>
    </ul>
  </li>
  <li>
    <p class="a" align="left">If there are no more bytes for a particular level, use zero for the that level.</li>
  <li>
    <p class="a" align="left">If there are no more bytes for all levels, stop.</li>
</ul>
<p class="a" align="left"><i>Example:</i></p>
<table border="1">
  <tr>
    <th>Fraction Collation Element</th>
    <th>UCA Collation Element</th>
    <th>In Sort Key</th>
  </tr>
  <tr>
    <td>[12 02 C4, 78, 03]</td>
    <td>[1202.7802.0302], [.C402.0000.0000]</td>
    <td>[12 02 C4 02 <b>00 00</b> 78 02 <b>00 00</b> 03 02]</td>
  </tr>
</table>
<p class="a" align="left">Using this transformation, two fractional collation elements will have the same relative ordering as their derived UCA collation 
element sequences. Because the fractional collation elements can handle all Unicode code points (even supplementary code points, above U+FFFF), so can the 
derived UCA collation elements sequences.</p>
<p class="a" align="left">All but the first collation element in the derived sequence are called <i>continuation collation elements.</i> If you now look back at 
the discussions in <a href="http://www.unicode.org/unicode/reports/tr10/#Large Weight Values">Section 6.2 Large Weight Values</a>, <a
href="http://www.unicode.org/unicode/reports/tr10/#Escape hatch">6.3.2 Escape Hatch</a>, and <a
href="http://www.unicode.org/unicode/reports/tr10/#LegalCodePoints">7.1.2 Legal code points</a>, you will see continuation collation elements that implicitly 
represent fractional collation elements.</p>
<p class="q" align="left">Q: Aren't the continuation collation elements in the above example ill-formed?</p>
<p class="a" align="left">The text of the UCA is not as clear as it should be on that point. It says:</p>
<blockquote>
  <p class="a" align="left">Except in special cases, no collation element can have a zero weight at Level N and a non-zero weight at Level N-1. Any collation 
  elements that violate this rule are called <i>ill-formed</i>. The reason for this will be explained under Step 4 of the main algorithm.</p>
</blockquote>
<p class="a" align="left">The &quot;special cases&quot; referred to in the text are <i>precisely</i> the continuation collation elements that would result from 
generating the collation element table from a fractional collation element table. A reformulation in terms of fractional collation elements clears this up.</p>
<p class="q" align="left">Q: In tailoring, I need to put a collation element between two others. How can I do this without changing the original two values?</p>
<p class="a" align="left">The easiest way to do this is to view the collation element table as fractional collation elements, as described in the previous 
questions. If you construct your original table so that you leave a bit of room between adjacent collation elements, then you can always find intermediate 
values for the weights at any level.</p>
<p class="q" align="left">Q: What do you mean by &quot;a bit of room&quot;?</p>
<p class="a" align="left">For two adjacent collation elements in the table, just make sure that for each level there is at least one <i>valid, extensible</i> 
fractional weight between the weights from those elements. (Extensible means that the weight could be of any length, e.g. without breaking R2.)</p>
<p class="a" align="left"><i>Example:</i></p>
<ul>
  <li>
    <p class="a" align="left"><b>AB C3</b> and <b>AB D0</b> have room:
    <ul>
      <li>
        <p class="a" align="left">One could insert 13 different 2-byte fractions: <b>AB C4, AB C5, ..., AB CC;</b> or many more 3 or more byte fractions.</li>
    </ul>
  </li>
  <li>
    <p class="a" align="left"><b>AB CD</b> and <b>AB CF</b> have room:
    <ul>
      <li>
        <p class="a" align="left">One could insert <b>AB CE</b>, or one could insert many more 3-byte fractions: <b>AB CE 02, AB CE 03, ...</b></li>
    </ul>
  </li>
  <li>
    <p class="a" align="left"><b>AB CD</b> and <b>AB CE</b> don't have room.
    <ul>
      <li>
        <p class="a" align="left">While fractions of the form <b>AB CD xx</b> are between these values, they would violate <b>R2</b> above.</li>
    </ul>
  </li>
  <li>
    <p class="a" align="left"><b>AA FF</b> and <b>AB 02</b> don't have room.
    <ul>
      <li>
        <p class="a" align="left">Inserting <b>AA FF xx</b> or <b>AB</b> would violate <b>R1.</b></li>
      <li>
        <p class="a" align="left">inserting <b>AB 00</b> or <b>AB 01</b> would violate <b>R2</b>.</li>
    </ul>
  </li>
</ul>
<p class="q" align="left">Q: So how do I determine the intermediate values?</p>
<p class="a" align="left">First, determine how many weights you need, and then how many valid weights are between the two given weights. Unless the fractional 
weights have the same number of bytes <i>and</i> only differ in the last byte, there will usually be far more weights than you need.&nbsp;If you know more about 
the relative frequency of the characters in text, you can choose shorter weights for the more frequent weights.</p>
<p class="a" align="left">More precisely, see <a href="#Intermediate_CEs">Intermediate CEs</a>.</p>
<p class="q" align="left">Q: I use the mechanisms in <a href="#L2/L3 in 8 bits">UCA ยง6.1.2, L2/L3 in 8 bits</a> to reduce my sort-key to less than half the 
size. How can I use this continuation/tailoring method with bytes instead of wydes?</p>
<p class="a" align="left">In the above, instead of adding <b>02</b> to odd-byte-length weights, leave the bytes zero. When composing the sort key, just omit any 
zero bytes when composing the sort key. Use <b>01</b> for the LEVEL_SEPARATOR. Thus the above example would become the considerably shorter key below:</p>
<table border="1">
  <tr>
    <th>&nbsp;</th>
    <th>Fraction Collation Element</th>
    <th>UCA Collation Element</th>
    <th>In Sort Key</th>
  </tr>
  <tr>
    <th>Old</th>
    <td>[12 02 C4, 78, 03]</td>
    <td>[1202.7802.0302], [.C402.0000.0000]</td>
    <td>[12 02 C4 02 <b>00 00</b> 78 02 <b>00 00</b> 03 02]</td>
  </tr>
  <tr>
    <th>New</th>
    <td>[12 02 C4, 78, 03]</td>
    <td>[1202.7800.0300], [.C400.0000.0000]</td>
    <td>[12 02 C4&nbsp; <b>01</b> 78 <b>01</b> 03]</td>
  </tr>
</table>
<h3 align="left">2.2 <a name="CollationElementFormat">Collation Element Format</a></h3>
<center>
<p align="left">ICU uses a single 32-bit value in the code and tables to represent a fractional collation element (FCE: see <a
href="#Fractional_Collation_Elements">Fractional Collation Elements</a>) into 32-bit chunks, in a way that can be easily used in generating sort keys. Since 
sometimes 32 bits is not enough, and sometimes exceptional processing must be handled, there are different forms of CE that distinguished by whether the first 
nybble is F or not.</p>
<h4 align="left"><a name="Normal_and_Continuation_Format">Normal and Continuation Format</a></h4>
<p align="left">The normal CE is of the following form. P is primary, S is secondary, C is case/continuation, and T is tertiary.</p>
<div align="center">
  <table border="1" cellspacing="1">
    <tr>
      <td class="primary"><font size="2">P</font></td>
      <td class="primary"><font size="2">P</font></td>
      <td class="primary"><font size="2">P</font></td>
      <td class="primary"><font size="2">P</font></td>
      <td class="primary"><font size="2">P</font></td>
      <td class="primary"><font size="2">P</font></td>
      <td class="primary"><font size="2">P</font></td>
      <td class="primary"><font size="2">P</font></td>
      <td class="primary"><font size="2">P</font></td>
      <td class="primary"><font size="2">P</font></td>
      <td class="primary"><font size="2">P</font></td>
      <td class="primary"><font size="2">P</font></td>
      <td class="primary"><font size="2">P</font></td>
      <td class="primary"><font size="2">P</font></td>
      <td class="primary"><font size="2">P</font></td>
      <td class="primary"><font size="2">P</font></td>
      <td class="secondary"><font size="2">S</font></td>
      <td class="secondary"><font size="2">S</font></td>
      <td class="secondary"><font size="2">S</font></td>
      <td class="secondary"><font size="2">S</font></td>
      <td class="secondary"><font size="2">S</font></td>
      <td class="secondary"><font size="2">S</font></td>
      <td class="secondary"><font size="2">S</font></td>
      <td class="secondary"><font size="2">S</font></td>
      <td class="case"><font size="2">C</font></td>
      <td class="case"><font size="2">C</font></td>
      <td class="tertiary"><font size="2">T</font></td>
      <td class="tertiary"><font size="2">T</font></td>
      <td class="tertiary"><font size="2">T</font></td>
      <td class="tertiary"><font size="2">T</font></td>
      <td class="tertiary"><font size="2">T</font></td>
      <td class="tertiary"><font size="2">T</font></td>
    </tr>
    <tr>
      <td colspan="16" class="primary">16b</td>
      <td colspan="8" class="secondary">8b</td>
      <td class="case" colspan="2">&nbsp;2b</td>
      <td colspan="6" class="tertiary">6b</td>
    </tr>
  </table>
</div>
<p align="left">The first nybble of the primary can never be F; this constraint is maintained by the data builder. The Case/Continuation value are used for two 
purposes: as a case value, or to indicate a continuation. When used for case, it can either be used as part of the case level, or considered part of the 
tertiary weight. In either case, a parameter can be used to invert it, thus changing whether small is before large or the reverse. That parameter can be either 
set in the rules or by a set call.</p>
<div align="center">
  <center>
  <table border="1" cellspacing="0" cellpadding="2">
    <tr>
      <th align="left">CC</th>
      <th align="left">Group</th>
      <th align="left">Description</th>
    </tr>
    <tr>
      <td>00</td>
      <td>Small</td>
      <td>lowercase letters, uncased letters, and small kana</td>
    </tr>
    <tr>
      <td>01</td>
      <td>Mixed</td>
      <td>a mixture of small and large. Does not occur in the UCA, but may occur in contractions, such as &quot;Ch&quot; in Slovak.</td>
    </tr>
    <tr>
      <td>10</td>
      <td>Large</td>
      <td>uppercase letters and large kana</td>
    </tr>
    <tr>
      <td>11</td>
      <td>Continuation</td>
      <td>Continuation CEs can <i>only</i> occur in Expansions (although not all Expansion CEs will be Continuations).<br>
        A continuation is used when the entire fraction for any of the weight levels cannot fit into one CE.</td>
    </tr>
  </table>
  </center>
</div>
<blockquote>
  <p align="left"><i>Note: </i>to meet validity constraints, a tertiary can only be zero (IGNORE) if the primary <i>and</i> secondary are zero; the secondary 
  can only be zero if the primary is zero. This constraint is managed by the data builder.</p>
</blockquote>
<h4 align="left"><a name="Special_Format">Special Format</a></h4>
<p align="left">The special CE is of the following form (where T = tag, d = data). The first nybble is F, to distinguish it from other cases. These are <i>only</i> 
used internal to the data table.</p>
<table border="1" cellspacing="1">
  <tr>
    <td class="flag">F</td>
    <td class="flag">F</td>
    <td class="flag">F</td>
    <td class="flag">F</td>
    <td class="case">T</td>
    <td class="case">T</td>
    <td class="case">T</td>
    <td class="case">T</td>
    <td class="primary">d</td>
    <td class="primary">d</td>
    <td class="primary">d</td>
    <td class="primary">d</td>
    <td class="primary">d</td>
    <td class="primary">d</td>
    <td class="primary">d</td>
    <td class="primary">d</td>
    <td class="primary">d</td>
    <td class="primary">d</td>
    <td class="primary">d</td>
    <td class="primary">d</td>
    <td class="primary">d</td>
    <td class="primary">d</td>
    <td class="primary">d</td>
    <td class="primary">d</td>
    <td class="primary">d</td>
    <td class="primary">d</td>
    <td class="primary">d</td>
    <td class="primary">d</td>
    <td class="primary">d</td>
    <td class="primary">d</td>
    <td class="primary">d</td>
    <td class="primary">d</td>
  </tr>
  <tr>
    <td colspan="4" class="flag">4b</td>
    <td colspan="4" class="case">4b Tag</td>
    <td colspan="24" class="primary">24 bit data</td>
  </tr>
</table>
<p>The tags have the values:</p>
<table border="1">
  <tr>
    <th align="left">NOT_FOUND_TAG</th>
    <td><b>0</b></td>
  </tr>
  <tr>
    <th align="left">EXPANSION_TAG</th>
    <td><b>1</b></td>
  </tr>
  <tr>
    <th align="left">CONTRACTION_TAG</th>
    <td><b>2</b></td>
  </tr>
  <tr>
    <th align="left">THAI_TAG</th>
    <td><b>3</b></td>
  </tr>
  <tr>
    <th align="left">CHARSET_TAG</th>
    <td><b>4</b></td>
  </tr>
  <tr>
    <th align="left">SURROGATE_TAG</th>
    <td><b>5</b></td>
  </tr>
  <tr>
    <th align="left">reserved</th>
    <td><b>6+</b></td>
  </tr>
</table>
</center>
<p align="left">To test whether a ce is an extension CE, we use:</p>
<div align="left">
  <pre align="left">if (ce &gt;= MIN_SPECIAL) ...</pre>
</div>
<h2 align="left">3 <a name="Forming_Sort_Keys">Forming Sort Keys</a></h2>
<pre align="left">const int CONTINUATION_MASK = 0x80;
const int CASE_MASK = 0x40;

const int MIN_SPECIAL = 0xF0000000;
const int MIN_VALUE = 0x02;
const int UNMARKED = 0x03;
</pre>
<p align="left">The following sample shows how this would work in practice. (ScriptOrder will be explained later).</p>
<div align="left">
  <pre>// once we have a cc. Special CEs have already been handled.

continuation = (ce &amp; 0x80) != 0;
ce ^= caseSwitch;         // handle case bit, switching
caseBit = ce &amp; CASE_MASK;

wt = ce &amp; tertiaryMask;
ws = (ce &gt;&gt; 8) &amp; 0xFF;
wp2 = (ce &gt;&gt; 16) &amp; 0xFF; // second primary byte
wp1 = (ce &gt;&gt; 24); // first primary byte

if (scriptOrder != null &amp;&amp; !continuation) {
  wp1 = scriptOrder[wp1];
}

if (wp1 != 0) *primary++ = wp1;
if (wp2 != 0) *primary++ = wp2;
if (doSecondary) {
  if (ws != 0) *secondary++ = ws;
  if (doTertiary) {
    if (wt != 0) *tertiary++
  }
}</pre>
</div>
<div align="left">
  <blockquote>
    <p><b>Note: </b>in practice, the speed of collation is very dependent on the number of instructions in the inner loops. We will have a separate version of 
    the loop that we will use for the common case: TERTIARY, no extra case level, IGNORABLE = ON. As it turns out, this is a very significant performance win. 
    We may add other special-case loops as well.</p>
  </blockquote>
</div>
<h3 align="left">3.1 <a name="French">French</a></h3>
<p align="left">If the FrenchSecondary flag is turned on, then the secondary values in the continuation CEs are reversed. This is so that when the secondary 
buffer itself is reversed (see below), the continuation values come out in the right order. This is done by the following pseudocode (where specialHandling is 
above)</p>
<div align="left">
  <pre align="left">if ((ce &amp; FLAGS_MASK) == CONTINUATION_MASK) {
  if (frenchStartPtr == null) frenchStartPtr = secondary - 1;
  frenchEndPtr = secondary + 1;
} else if (frenchStartPtr != null) {
  //reverse secondaries from frenchStartPtr up to frenchEndPtr
}</pre>
</div>
<p align="left">plus some code at the very end, after processing all CEs, to catch the final case.</p>
<div align="left">
  <pre align="left">if (frenchStartPtr != null) {
  //reverse secondaries from frenchStartPtr up to frenchEndPtr
}</pre>
</div>
<blockquote>
  <p align="left"><b>Note: </b>In incrementally comparing strings, as opposed to sort keys, more work has to be done with French secondaries. Essentially, all 
  the secondaries are buffered up, and if there is no primary difference they are compared in reverse order. See <a href="#String_Compare">String Compare</a>.</p>
</blockquote>
<h3 align="left">3.2 <a name="Quarternary">Quarternary</a></h3>
<p align="left">In the collation table, there is a value VARIABLE_MAX. All CEs with primary weights between zero and VARIABLE_MAX&nbsp; are considered to be 
variable. (This saves having a bit per CE!) If a CE is variable, we support the Shifted Option from the UCA in constructing. We process the UCA table to ensure 
that VARIABLE_MAX&nbsp; has a zero second byte for simplicity, but a tailored or parametric Variable_Max may have two bytes. (We do impose the restriction that 
it can't have more.)</p>
<p align="left">The quarternary is computed based on the setting. With shifted, then it is skipped if the ce is entirely zero, equal to the primary if variable, 
and otherwise equal to FF. (In the UCA this is FFFF, but we can make it a single-byte weight.) In either case, the quarternary is compressed (see below).</p>
<p align="left">If we are not doing a quarternary level, and the CE is variable, then it is simply ignored (treated as zero). That requires some amendment to 
the code above, since we have to make a check before we start adding to the primary.</p>
<p align="left">The code for the quarternary itself looks something like the following:</p>
<div align="left">
  <pre align="left">if (doQuarternary) { // fourth  level
&nbsp;&nbsp;&nbsp; if (continuation &amp;&amp; lastWasVariable
        || (wp1&nbsp;&lt;=  variableMax1 &amp;&amp; wp1 &gt; 0 // exclude common cases in first  test
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   &amp;&amp; (wp1  &lt;&nbsp;variableMax1 || wp1  == variableMax1 &amp;&amp; wp2 &lt;= variableMax2))) {
      *quarternary++ = wp1;
      if (wp2 != 0) *quarternary++ = wp2;
      lastWasVariable = true;
&nbsp;&nbsp;&nbsp; } else {
      // do normal weights, plus
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if (doQuarternary) *quarternary++ = 0xFF;
      lastWasVariable = false;
&nbsp;&nbsp;&nbsp; }
} else {
  // do normal weights
}</pre>
</div>
<blockquote>
  <p align="left"><b>Note: </b>We have to remember if the last CE was a variable, just in case we had a continuation.</p>
</blockquote>
<h3 align="left">3.3 <a name="Case_Handling">Case Handling</a></h3>
<p align="left">In the UCA and tailoring, we have computed a case bit. This bit is set ON based on character properties, not based on the tailoring or UCA 
ordering. In particular, the case bit is set ON for a string if and only if there is at least one character in the NKFD form of that string which either has a 
lowercase, or has a corresponding small kana form. For sample code for computing that in the UCA processing, see <a href="#uca">UCA Case Bit</a>. We precompute 
certain values and store them in the collation object:</p>
<div align="left">
  <pre align="left">ce ^= caseSwitch;
wt = ce &amp; tertiaryMask;</pre>
</div>
<p align="left">The caseSwitch value is set to 0x80 iff UPPER_FIRST is set in the parameters (or it may come from the tailoring table, if DEFAULT is used). It 
is used <i>after</i> the continuation bits are discarded. It thus has the effect of changing Small to Large, Large to Small, and leaving Mixed alone.</p>
<blockquote>
  <p align="left"><b>Note: </b>There is a restriction on the effect of UPPER_FIRST. If you have contractions such as ch, Ch, hC, CH, then both the Ch and cH 
  will be treated as Mixed, and thus be unaffected by UPPER_FIRST.</p>
</blockquote>
<p align="left">The tertiaryMask value is normally set to 0x3F, to discard the case bit in tertiary values. It is set to 0x7F when the caseLevel is OFF, and we 
have either UPPER_FIRST or LOWER_FIRST.</p>
<p align="left">If the caseLevel is ON, then we generate an intermediate level. This is targetted at the small/large difference for Japanese. Since we know that 
the case occupies exactly one bit, we optimize this (at the expense of some code) by storing it bit at a time (with one bit overhead per byte). That is, 7 or 
fewer letters in the string only take 1 byte; 14 or fewer 2 bytes, etc. The reason we have the extra bit is so that the separator value between levels is 
distinguished. The code will look something like:</p>
<pre>// when creating the level keys

int caseShift = 0;
...
if (caseLevel) {
  if (caseShift  == 0) {
    *case++ = 0x80;
    caseShift = 7;
  }
  case[-1] |= (wt &amp; 0x80) &gt;&gt; caseShift--;
}</pre>
<h3 align="left">3.4 <a name="Compression">Compression</a></h3>
<p align="left">We will use the technique discussed in UCA to reduce the length of sort keys that contain a series of common weights in non-primary positions. 
This produces very significant reductions in sort key size, since most secondary, tertiary, and quarternary weights are UNMARKED. (Primary weights are also 
compressed: see <a href="#Appendix_2">Appendix 2</a> for a description of how that is done.)</p>
<p align="left">We make sure there are no real weights that are both greater than COMMON (abbreviated by C below) and less than or equal to COMMON_TOP (abbr. 
T). Then look at a series of COMMON bytes followed by bytes H (higher than C) or L (lower than C), or nothing. Here is the ordering, and the compression that 
also produces that ordering. For illustration, the gap between T and has been artificially set to a small number to illustrate what happens if the normal 
compression range is exceeded.</p>
<div align="center">
  <center>
  <table border="1" cellspacing="1" cellpadding="4">
    <tr>
      <th colspan="5">Original Bytes</th>
      <th colspan="3">Result Bytes</th>
    </tr>
    <tr>
      <td class="secondary" width="12%">C</td>
      <td class="secondary" width="12%">H</td>
      <td class="secondary" width="12%">&nbsp;</td>
      <td class="secondary" width="12%">&nbsp;</td>
      <td class="secondary" width="12%">&nbsp;</td>
      <td class="case" width="12%">T</td>
      <td class="case" width="12%">H</td>
      <td class="case" width="12%">&nbsp;</td>
    </tr>
    <tr>
      <td class="secondary">C</td>
      <td class="secondary">C</td>
      <td class="secondary">H</td>
      <td class="secondary">&nbsp;</td>
      <td class="secondary">&nbsp;</td>
      <td class="case">T-1</td>
      <td class="case">H</td>
      <td class="case">&nbsp;</td>
    </tr>
    <tr>
      <td class="secondary">C</td>
      <td class="secondary">C</td>
      <td class="secondary">C</td>
      <td class="secondary">H</td>
      <td class="secondary">&nbsp;</td>
      <td class="case">T-2</td>
      <td class="case">H</td>
      <td class="case">&nbsp;</td>
    </tr>
    <tr>
      <td class="secondary">C</td>
      <td class="secondary">C</td>
      <td class="secondary">C</td>
      <td class="secondary">C</td>
      <td class="secondary">H</td>
      <td class="case">T-3</td>
      <td class="case">T</td>
      <td class="case">H</td>
    </tr>
    <tr>
      <td class="secondary">C</td>
      <td class="secondary">C</td>
      <td class="secondary">C</td>
      <td class="secondary">C</td>
      <td class="secondary">L</td>
      <td class="case">C+3</td>
      <td class="case">C</td>
      <td class="case">L</td>
    </tr>
    <tr>
      <td class="secondary">C</td>
      <td class="secondary">C</td>
      <td class="secondary">C</td>
      <td class="secondary">C</td>
      <td class="secondary">&nbsp;</td>
      <td class="case">C+3</td>
      <td class="case">C</td>
      <td class="case">&nbsp;</td>
    </tr>
    <tr>
      <td class="secondary">C</td>
      <td class="secondary">C</td>
      <td class="secondary">C</td>
      <td class="secondary">L</td>
      <td class="secondary">&nbsp;</td>
      <td class="case">C+2</td>
      <td class="case">L</td>
      <td class="case">&nbsp;</td>
    </tr>
    <tr>
      <td class="secondary">C</td>
      <td class="secondary">C</td>
      <td class="secondary">C</td>
      <td class="secondary">L</td>
      <td class="secondary">&nbsp;</td>
      <td class="case">C+2</td>
      <td class="case">L</td>
      <td class="case">&nbsp;</td>
    </tr>
    <tr>
      <td class="secondary">C</td>
      <td class="secondary">C</td>
      <td class="secondary">C</td>
      <td class="secondary">&nbsp;</td>
      <td class="secondary">&nbsp;</td>
      <td class="case">C+2</td>
      <td class="case">&nbsp;</td>
      <td class="case">&nbsp;</td>
    </tr>
    <tr>
      <td class="secondary">C</td>
      <td class="secondary">C</td>
      <td class="secondary">L</td>
      <td class="secondary">&nbsp;</td>
      <td class="secondary">&nbsp;</td>
      <td class="case">C+1</td>
      <td class="case">L</td>
      <td class="case">&nbsp;</td>
    </tr>
    <tr>
      <td class="secondary">C</td>
      <td class="secondary">C</td>
      <td class="secondary">&nbsp;</td>
      <td class="secondary">&nbsp;</td>
      <td class="secondary">&nbsp;</td>
      <td class="case">C+1</td>
      <td class="case">&nbsp;</td>
      <td class="case">&nbsp;</td>
    </tr>
    <tr>
      <td class="secondary">C</td>
      <td class="secondary">L</td>
      <td class="secondary">&nbsp;</td>
      <td class="secondary">&nbsp;</td>
      <td class="secondary">&nbsp;</td>
      <td class="case">C</td>
      <td class="case">L</td>
      <td class="case">&nbsp;</td>
    </tr>
    <tr>
      <td class="secondary">C</td>
      <td class="secondary">&nbsp;</td>
      <td class="secondary">&nbsp;</td>
      <td class="secondary">&nbsp;</td>
      <td class="secondary">&nbsp;</td>
      <td class="case">C</td>
      <td class="case">&nbsp;</td>
      <td class="case">&nbsp;</td>
    </tr>
  </table>
  </center>
</div>
<p align="left">To do this in code, we replace a statement like:</p>
<div align="left">
  <pre>*secondary++ = ws;</pre>
</div>
<p align="left">we write:</p>
<div align="left">
  <pre>if (ws  == COMMON2) {
  ++count2;
} else {
  if (count2 &gt; 0) {
    writeCompressed2();
    count2 = 0;
  }
  *secondary++ = ws;
}

void writeCompressed2() {
  if (ws &gt; COMMON2) { // not necessary for 4th level.
    while (count2 &gt;= MAX_TOP2) {
      *secondary++ = COMMON_TOP2 - TOP_COUNT2;
      count2 -= TOP_COUNT2;
    }
    *secondary++ = COMMON_TOP2 - count2;
  } else {
    while (count2 &gt;= BOT_COUNT2) {
      *secondary++ = COMMON_BOT2 + BOT_COUNT2;
      count2 -= BOT_COUNT2;
    }
    *secondary++ = COMMON_BOT2 + count2;
  }
}</pre>
</div>
<p align="left"><b>Note: if count2 &gt; 0, then </b>writeCompressed <b>also</b> needs to be called at the very end of the sortkey generation. Similar code is 
used for tertiaries and quarternaries, with different values for the constants. MAX_TOP is derived from the other values:</p>
<ul>
  <li>
    <p align="left">TOTAL_COUNT = COMMON_TOP - COMMON_BOT - 1</li>
  <li>
    <p align="left">TOP_COUNT = TOP_FACTORn * TOTAL_COUNT</li>
  <li>
    <p align="left">BOT_COUNT = TOTAL_COUNT - TOP_COUNT</li>
</ul>
<p align="left">The choice of how much space to put in MAX_TOP vs MAX_BOT depends on the relative frequency of H vs L bytes following. Remember that 
&quot;nothing&quot; counts as an L byte. For all of the values, see <a href="#Magic_Bytes">Magic Bytes</a>.</p>
<p align="left">Secondaries</p>
<ul>
  <li>
    <p align="left">In the processing of the secondaries for the Fractional UCA, we will allocate a gap of 0x80</li>
</ul>
<p align="left">Tertiaries</p>
<ul>
  <li>
    <p align="left">If UPPER_FIRST or LOWER_FIRST is used, we will take the 8 bits from tertiaries (including the case/continuation bits) from a CE, The top 
    0x40 values are continuation bits. Those are discarded, and a gap of 0x40 is used.</li>
  <li>
    <p align="left">Otherwise, 6 bits are taken from the tertiaries (excluding the case/continuation bits), and we allocate a gap of 0x80.</li>
</ul>
<p align="left">Quarternaries:</p>
<ul>
  <li>
    <p align="left">Since there are never any higher bytes than FF, TOP_COUNT in that case is zero, and the code could be slightly simpler.</li>
  <li>
    <p align="left">TOP_COUNT is computed from VariableTop. Take the first byte of VariableTop, and add 1 to it.</li>
</ul>
<h3 align="left">3.5 <a name="Stack_Buffers">Stack Buffers</a></h3>
<p align="left">We can use stack buffers for almost all cases. The vast majority of sorted strings are fairly small, so we optimize for that. Here's basically 
how this is done..</p>
<div align="left">
  <pre>// allocate buffers
#define BUFFER_SIZE 1000
char primaryBuffer[BUFFER_SIZE];
char secondaryBuffer[BUFFER_SIZE];
char tertiaryBuffer[BUFFER_SIZE];
char caseBuffer[BUFFER_SIZE];
char quarternaryBuffer[BUFFER_SIZE];

// initialize buffers, normally to stack
int max;
boolean allocatedPrimary = false, allocatedSecondary = false...

char* primary  = *primaryStart = outputBuffer; // write into output buffer, if large enough
max = getMaxPrimaryFactor() * sourceLength;
if (max &gt; BUFFER_SIZE) primary = primaryStart = malloc(max);
else if (max &gt; outputLength) primary = primaryStart = primaryBuffer;

char* secondary = secondaryBuffer;
max = getMaxSecondaryFactor() * sourceLength;
if (max &gt; BUFFER_SIZE) secondary = secondaryStart = malloc(max);</pre>
</div>
<div align="left">
  <pre>// tertiary, case, quarternary like secondary.</pre>
</div>
<div align="left">
  <pre>...// do code</pre>
</div>
<div align="left">
  <pre>// clean up after copying contents to output</pre>
</div>
<div align="left">
  <pre>if (primaryStart != outputBuffer &amp;&amp; primaryStart != primaryBuffer) delete(primaryStart);
if (secondaryStart != secondaryBuffer) delete(secondaryStart);
if (tertiaryStart != tertiaryBuffer) delete(tertiaryStart);
if (caseStart != caseBuffer) delete(caseStart);
if (quarternaryStart != quarternaryBuffer) delete(quarternaryStart);</pre>
</div>
<p align="left">By handling it this way, we don't need to do any error checking in the loop for buffers being too small.</p>
<h3 align="left">3.6 <a name="Appending_Levels">Appending Levels</a></h3>
<p align="left">Once we have the level keys, we put them into the sort key. We keep separate buffers for each one. The primary buffer is initially the result 
buffer for the function; that saves a later copy. In the normal case, we fill each buffer, then append the secondary, tertiary, etc. to the result buffer. We 
normally use stack buffers for all of these; only if the result would be larger do we allocate a temporary buffer (divided into pieces internally) that we use 
for our results. This temporary buffer is deallocated at the end. However, in normal operation this should not occur; it is only for graceful degradation.</p>
<p align="left">We support preflighting; if the result overflows the result buffer, then we set the appropriate error, but also return the length it would have 
had. This is done by switching to an alternate routine that just counts bytes (and adds them to the bytes we already had.</p>
<p align="left">We use buffers large enough that we can avoid making multiple tests on buffer sizes per character.</p>
<blockquote>
  <p align="left"><b>Note: </b>LEVEL_SEPERATOR is 01, not 00 (as in the previous version of&nbsp; ICU). All sort weights are constructed to avoid the 01 bytes 
  so that 01 can be used as the separator. This allows the resulting sort key to be a C string (no null bytes except for a terminating null byte). This means 
  that the sort keys can be compared with strcmp (on platforms where strcmp uses, or behaves as if it uses, unsigned bytes).</p>
</blockquote>
<h3 align="left">3.7 <a name="Identical_Strength">Identical Strength</a></h3>
<p>For IDENTICAL strength, we append the (normalized) string to the end of the sort key. The string is processed using a variant of <a href="bocu.htm">BOCU</a> 
(called BOSCU).</p>
<blockquote>
  <p><b>Note: </b>The IDENTICAL strength is <i>not</i> recommended for general use. Some people believe that it makes the sort stable: that is a 
  misapprehension: a stable sort is one where equal records come out in the same order as they were put in. This requires more than simply distinguishing 
  strings that are the same for the primary, secondary and tertiary weights. A common solution is to append the record number to the sort key.</p>
</blockquote>
<h2 align="left">4 <a name="String_Compare">String Compare</a></h2>
<p align="left">String compare uses an incremental algorithm. The goal is to minimize the work if possible, instead of building two sort keys and doing a binary 
compare. The latter, however, is an escape valve; for rare cases that would be complicated to support, we fall back to that.</p>
<p align="left">In the old ICU we had a rather complex algorithm to do the comparison. The problem comes in with dealing with ignorables โ at each level. We 
now simplify the algorthm. Basically, we do the following;&nbsp;</p>
<ol>
  <li>
    <p align="left">compare initial characters
    <ul>
      <li>
        <p align="left">loop through the characters in both strings until a binary difference is found</li>
      <li>
        <p align="left">backup if we have to (see below)</li>
    </ul>
  </li>
  <li>
    <p align="left">loop comparing the primaries.
    <ul>
      <li>
        <p align="left">fetch CEs for each string successively
        <ul>
          <li>
            <p align="left">if either is ignoreable, stuff its CE into a buffer and fetch another.</li>
          <li>
            <p align="left">repeat until neither is ignorable.</li>
        </ul>
      </li>
      <li>
        <p align="left">if the primaries are different, return the ordering</li>
      <li>
        <p align="left">otherwise, check for END_CE (returned by FetchCE at end of string), and break out of this loop</li>
      <li>
        <p align="left">otherwise stuff the CEs into two buffers for later, and loop to #2</li>
    </ul>
  </li>
  <li>
    <p align="left">loop through the secondaries in the buffers.
    <ul>
      <li>
        <p align="left">For French, we go in reverse order. Continuations need special processing to get the order right.</li>
      <li>
        <p align="left">Skip any ignorable secondaries; otherwise return if there are any differences.</li>
    </ul>
  </li>
  <li>
    <p align="left">loop through the case bits in the buffers.
    <ul>
      <li>
        <p align="left">Skip any ignorable tertiary; otherwise return if there are any differences.</li>
    </ul>
  </li>
  <li>
    <p align="left">loop through the tertiaries in the buffers.
    <ul>
      <li>
        <p align="left">Skip any ignorable tertiary; otherwise return if there are any differences.</li>
    </ul>
  </li>
  <li>
    <p align="left">loop through the quarternaries.</li>
  <li>
    <p align="left">compare the binary, normalized string (see <a href="#Identical_Strength">Identical Strength</a>)</li>
</ol>
<p align="left">In the above process, we skip any step unless the parameters call for it. So the normal case will do&nbsp;#1, #2, #3, #5, stopping if there is 
any difference. If we ever have a buffer overflow, we just bail to comparing sortkeys. (This will be extremely rare in practice). We put special terminating 
values in the buffers so that we can easily recognize the end.</p>
<p align="left">If normalization is ON, then we will first check with <a href="#CheckFCD">checkFCD</a> to see if we need to normalize; only if we really need to 
will we call the normalization process.</p>
<h3 align="left">4.1 <a name="Backup">Backup</a></h3>
<p align="left">It pays to check for identical prefixes with a binary compare, just because it is so simple to do, and is a fairly common case. Once we find a 
common initial substring, we may have to backup in some circumstances to a &quot;safe&quot; position. Here are examples of unsafe characters, in the third 
column:</p>
<table border="1">
  <tr>
    <th>Type</th>
    <th colspan="2">Example</th>
  </tr>
  <tr>
    <td>Contraction (Spanish)</td>
    <td>c</td>
    <td><font size="3">h</font></td>
  </tr>
  <tr>
    <td>Normalization</td>
    <td>a</td>
    <td><font size="3">ยฐ</font></td>
  </tr>
  <tr>
    <td>Surrogate</td>
    <td>&nbsp;</td>
    <td>&lt;S&gt;</td>
  </tr>
</table>
<p align="left"><b>Contractions. </b>Suppose we have &quot;ch&quot; as a contraction, so that &quot;charo&quot; &gt; &quot;czar&quot;. Then when we hit the 
difference at &quot;h&quot; and &quot;z&quot; we can't just compare the rest of the strings &quot;haro&quot; and &quot;zar&quot;: we would get the wrong answer. 
We have to backup by one. We have to repeat the test, because the position we backup to may also be in the middle of a contraction. So the way we do this is to 
flag every character that is a trailing character in some contraction. (A trailing character is any but the first).</p>
<p align="left"><b>Normalization and Canonical Order. </b>To get to a safe position, we backup if the character after the pointer is a MAYBE in the NFC 
QuickCheck table, or has non-zero combining class.</p>
<p align="left"><b>Surrogates. </b>Since supplementary characters are exceedingly rare, to simplify our processing we will simply backup if the code unit after 
the pointer is either a Lead or Trail surrogate: anything in D800..DFFF. To avoid clogging the unsafe table, this will just use a range check, and no 
supplementary characters will be in the unsafe table.</p>
<p align="left">Because we will not normally need to backup <i>and the whole purpose of the initial check is for performance</i>, we don't waste time trying to 
find out exactly the circumstances where we need to backup. So we can err on the side of backing up more than we theoretically have to, to reduce the 
computation. We just keep a simple bit table in the tailoring table. This table contains a set of flags that mark a <b>code unit</b> (UTF-16) is flagged as 
&quot;unsafe&quot;.</p>
<p align="left">To make the table smaller, we actually just hash codes into the table. This may cause us to back up slightly more often, but that will not be a 
correctness issue. We do this if the character is marked as &quot;unsafe&quot; either in the UCA or in the tailoring. (We might later copy the contents of the 
UCA into the tailoring table.) The first 256 bits are reserved for Latin-1, to avoid collisions.</p>
<h2>5 <a name="Data_Tables">Data Tables</a></h2>
<p>A collation table, whether UCA or a tailored table, contains the following subtables. It is in a flattened form that can be loaded as a DLL or into read-only 
shared memory. The header contains offsets to all the other subtables, plus the number of items in each subtable, plus various information that is used in 
processing, such as the maximumPrimaryFactor. A CE is a uint32_t. A UChar is 16 bits.</p>
<blockquote>
  <p><b>Note:</b> we make the processing faster by having offsets everywhere in the table be from the very start of the whole table, not from the start of the 
  each subtable!</p>
  <p>The order of the subtables is not determined, with one exception: because the offsets to the Expansion table have only 20 bits, we put that one first. The 
  position of each table is determined by looking up the offset in the header.</p>
</blockquote>
<table border="0" cellspacing="0" cellpadding="4">
  <tr>
    <td align="center" valign="top" width="16%">
      <table border="1">
        <tr>
          <th width="100%">Header</th>
        </tr>
        <tr>
          <td width="100%">info...</td>
        </tr>
        <tr>
          <td width="100%">Expansions offset</td>
        </tr>
        <tr>
          <td width="100%">Expansions count</td>
        </tr>
        <tr>
          <td width="100%">MainยทIndex offset</td>
        </tr>
        <tr>
          <td width="100%">MainยทIndex count</td>
        </tr>
        <tr>
          <td width="100%">MainยทData offset</td>
        </tr>
        <tr>
          <td width="100%">MainยทData count</td>
        </tr>
        <tr>
          <td width="100%">Rules offset</td>
        </tr>
        <tr>
          <td width="100%">Rules count</td>
        </tr>
        <tr>
          <td width="100%">...</td>
        </tr>
      </table>
    </td>
    <td align="center" valign="top" width="16%">
      <table border="1">
        <tr>
          <th width="100%">Expansions</th>
        </tr>
        <tr>
          <td width="100%">CE</td>
        </tr>
        <tr>
          <td width="100%">CE</td>
        </tr>
        <tr>
          <td width="100%">CE</td>
        </tr>
        <tr>
          <td width="100%">...</td>
        </tr>
      </table>
    </td>
    <td align="center" valign="top" width="16%">
      <table border="1">
        <tr>
          <th width="100%">MainยทIndex</th>
        </tr>
        <tr>
          <td width="100%">index</td>
        </tr>
        <tr>
          <td width="100%">index</td>
        </tr>
        <tr>
          <td width="100%">...</td>
        </tr>
      </table>
      &nbsp;
      <table border="1" width="1%">
        <tr>
          <th width="100%">MainยทData</th>
        </tr>
        <tr>
          <td width="100%">CE</td>
        </tr>
        <tr>
          <td width="100%">CE</td>
        </tr>
        <tr>
          <td width="100%">CE</td>
        </tr>
        <tr>
          <td width="100%">CE</td>
        </tr>
        <tr>
          <td width="100%">CE</td>
        </tr>
        <tr>
          <td width="100%">CE</td>
        </tr>
        <tr>
          <td width="100%">...</td>
        </tr>
      </table>
    </td>
    <td align="center" valign="top" width="16%">
      <table border="1">
        <tr>
          <th width="100%">Contraction UChars</th>
        </tr>
        <tr>
          <td width="100%">c1</td>
        </tr>
        <tr>
          <td width="100%">c2</td>
        </tr>
        <tr>
          <td width="100%">c2</td>
        </tr>
        <tr>
          <td width="100%">...</td>
        </tr>
      </table>
      &nbsp;
      <table border="1">
        <tr>
          <th width="100%">Contraction Results</th>
        </tr>
        <tr>
          <td width="100%">CE1</td>
        </tr>
        <tr>
          <td width="100%">CE2</td>
        </tr>
        <tr>
          <td width="100%">CE3</td>
        </tr>
        <tr>
          <td width="100%">...</td>
        </tr>
        <tr>
          <td width="100%">&nbsp;</td>
        </tr>
      </table>
    </td>
    <td align="center" valign="top" width="16%">
      <table border="1">
        <tr>
          <th width="100%">Surrogate TrieยทIndex</th>
        </tr>
        <tr>
          <td width="100%">index</td>
        </tr>
        <tr>
          <td width="100%">index</td>
        </tr>
        <tr>
          <td width="100%">...</td>
        </tr>
      </table>
      &nbsp;
      <table border="1">
        <tr>
          <th width="100%">Surrogate TrieยทData</th>
        </tr>
        <tr>
          <td width="100%">CE</td>
        </tr>
        <tr>
          <td width="100%">CE</td>
        </tr>
        <tr>
          <td width="100%">CE</td>
        </tr>
        <tr>
          <td width="100%">CE</td>
        </tr>
        <tr>
          <td width="100%">CE</td>
        </tr>
        <tr>
          <td width="100%">CE</td>
        </tr>
        <tr>
          <td width="100%">...</td>
        </tr>
      </table>
    </td>
    <td align="center" valign="top" width="16%">
      <table border="1">
        <tr>
          <th width="100%">Rules</th>
        </tr>
        <tr>
          <td width="100%">...a &lt;&lt;&lt; A &lt; b &lt;&lt;&lt; B...</td>
        </tr>
      </table>
    </td>
  </tr>
</table>
<p align="left">Each of these tables is described in more detail in the section of Fetching CEs that deals with them.</p>
<h2 align="left">5 <a name="Fetching_CEs">Fetching CEs</a></h2>
<p align="left">getCE is a function that returns a single CE, based on a source buffer. It is used by the sort-key generator, for the incremental string 
comparison, and by the public iteration API. There is a parallel version that fetches CEs going backwards through a string. That version is used in the fast 
Boyer-Moore international search algorithm.</p>
<h3 align="left">5.1 <a name="General">General</a></h3>
<p align="left">Because two strings are &quot;live&quot; at the same time in comparison, we will pass in a parameter block (allocated on the stack) with state 
information for each string to getCE. This is called a <a name="Context">Context</a>:<o:p>          
  </o:p>                                                                                    
</p> 
<table border="1" cellspacing="0" cellpadding="2">
  <tr>
    <th align="left">source</th>
    <td>The source character position</td>
  </tr>
  <tr>
    <th align="left">sourceEnd</th>
    <td>To know when to end</td>
  </tr>
  <tr>
    <th align="left">ceBuffer</th>
    <td>For CEs that are results of expansion</td>
  </tr>
  <tr>
    <th align="left">ceBufferStart</th>
    <td>The start index for CEs in the buffer.</td>
  </tr>
  <tr>
    <th align="left">ceBufferEnd</th>
    <td>The limit index for CEs in the buffer</td>
  </tr>
  <tr>
    <th align="left">isThai</th>
    <td>Have we encountered Thai pre-vowel?</td>
  </tr>
</table>
<h4 align="left">ceBuffer</h4>
<p align="left">For each string, we keep a ceBuffer for expansions. This is a FIFO queue, allocated on the stack. It is large enough to handle all reasonable 
expansions (e.g. up to 100). We will not build longer expansions in the tables so we never need to check for overflows.</p>
<p align="left">There are two pointers: ceBufferStart and ceBufferEnd that point to the contents. The function is demonstrated below.</p>
<h4 align="left"><a name="Normalization">Normalization</a></h4>
<p align="left">For compliance with UCA, we have to get the same results as if the text is in NFD. However, in the majority of cases, we manage this without the 
performance cost (or extra buffer management) of actually doing the NFD conversion.</p>
<p align="left">In the normal case, we fetch characters directly from the source buffer. This is the case either if normalization is OFF, or if we had passed 
the <a href="#CheckFCD">CheckFCD</a> test. (Clients of the API should only turn normalization off if all the strings are guaranteed to be in FCD.)</p>
<p align="left">This testing is done at the very beginning of the routine, not within any loops. If we have to normalize, then we do so with NFD into a stack 
buffer (if possible). If too big to normalize into the stack buffer, we allocate a temporary buffer. This allocation should be rare, and will thus not be a 
performance issue. In either case, we reset the source pointer to point at the normalized text, so we do no extra work within the loops.</p>
<div align="left">
  <pre>// initialize
uchar* sourceBuffer [BUFFER_SIZE];
uchar* source, *sourceStart;
source = sourceStart = inputBuffer;
if (normalization_on &amp;&amp; !checkFCD(inputBuffer, inputLength) {
  // normalize into sourceBuffer if possible,  resetting source, sourceStart
  // if too big, allocate memory, resetting source, sourceStart
}
uchar* sourceEnd = source + sourceLength;
....
// cleanup
if (sourceStart != inputBuffer &amp;&amp; sourceStart != sourceBuffer) delete(sourceStart);</pre>
</div>
<h4><a name="CheckFCD">CheckFCD</a></h4>
<p>So what is checkFCD? We will start with a couple of definitions.</p>
<p>Define the <i>raw canonical decomposition</i> (RCD) of a string to be the result of replacing each character by its canonical decomposition, <i>without</i> 
canonical reordering.</p>
<ul>
  <li>The raw canonical decomposition may or may not be in NFD. It depends on whether there will be any combining marks that are not in canonical order.</li>
</ul>
<p>Define a string to be in <i>fast C or D (FCD)</i> if its raw canonical decomposition is of form NFD.</p>
<ul>
  <li>FCD is <i>not</i> a Normalization Form, since there is <b>no</b> uniqueness -- it is just defined here for the purposes of collation.</li>
</ul>
<p>Examples:</p>
<table border="1">
  <tr>
    <th>X</th>
    <th>FCD</th>
    <th>NFC</th>
    <th>NFD</th>
    <th>Comments on FCD</th>
  </tr>
  <tr>
    <td>A- ring</td>
    <td align="center">Y</td>
    <td align="center">Y</td>
    <td align="center">&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>Angstrom</td>
    <td align="center">Y</td>
    <td align="center">&nbsp;</td>
    <td align="center">&nbsp;</td>
    <td>RCD(X) == A + ring == NFD(X)</td>
  </tr>
  <tr>
    <td>A + ring</td>
    <td align="center">Y</td>
    <td align="center">&nbsp;</td>
    <td align="center">Y</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>A + grave</td>
    <td align="center">Y</td>
    <td align="center">&nbsp;</td>
    <td align="center">Y</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>A-ring + grave</td>
    <td align="center">Y</td>
    <td align="center">&nbsp;</td>
    <td align="center">&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>A + cedilla + ring</td>
    <td align="center">Y</td>
    <td align="center">&nbsp;</td>
    <td align="center">Y</td>
    <td>X == RCD(X) == NFD(X)</td>
  </tr>
  <tr>
    <td>A + ring + cedilla</td>
    <td align="center">&nbsp;</td>
    <td align="center">&nbsp;</td>
    <td align="center">&nbsp;</td>
    <td>X == RCD(X) != NFD(X) == A + ring + cedilla</td>
  </tr>
  <tr>
    <td>A-ring + cedilla</td>
    <td align="center">&nbsp;</td>
    <td align="center">Y</td>
    <td align="center">&nbsp;</td>
    <td>RCD(X) == A + ring + cedilla != NFD(X)</td>
  </tr>
</table>
<p>Note that all NFD strings are in FCD, and in practice most NFC strings will also be in FCD; for that matter <i>most</i> strings (of whatever ilk) will be in 
FCD.</p>
<p>We guarantee that if any input strings are in FCD, that we will get the right results in collation without having to normalize. We can do this because we do 
a canonical closure both in our Fractional UCA table and in our Tailoring table, and we handle Hangul decomposition algorithmically in <a
href="#Hangul_Implicit_CEs">Hangul Implicit CEs</a>. So any composite automatically expands as the correct series of CEs. If the string is FCD, then this 
expansion will be in the right order and everything is hunky-dory, even without normalization to NFD.</p>
<p>Luckily a test for FCD is even faster and more precise than Normalization <a href="http://www.unicode.org/unicode/reports/tr15/#Annex8">QuickCheck</a>. We 
have a static FCD data table that is precomputed to map each Unicode codepoint X to the combiningClass of the last character in the canonical decomposition for 
X. This table is constructed as a standard Trie. Then the code is something like:</p>
<pre>boolean checkFCD(uchar *p, uchar* endp) {
  uint8 lastFCD = 0;
  while (p &lt; endp) {
    uint8 fcd = FCD(*p++);
    if (fcd != 0 &amp;&amp; lastFCD &gt; fcd) return false;
    lastFCD = fcd;
  }
  return true;
}</pre>
<p>When we are dealing with null-terminated strings, we have to make a pass through the characters anyway to find the length so that we can set up the buffers 
properly. These two checks are combined into a single routine for performance.</p>
<blockquote>
  <p><b>Note: </b>The Unicode 2.1.9 UCA tables do not contain canonical closures. Formally speaking, NFD must be used for compliance to UCA, but the table also 
  contains specially constructed CEs for characters that have canonical decompositions. These special CEs are useful in certain environments where the input 
  format of strings is guaranteed to be constrained, and also supply a certain degree of compression. However, they handle a narrower range of strings without 
  normalization; the compression is smaller than what we get with other techniques; and most importantly, strings produced with normalization OFF are not 
  comparable to strings produced with it ON (unlike with canonical closures). The ISO 14651 tables do contain the canonical closures, as will the UCA tables in 
  the future.</p>
</blockquote>
<h4 align="left"><a name="Special_CEs">Special CEs</a></h4>
<p align="left">If the CE is of the form Ftyyyyyy, then it has a special interpretation. For specials,&nbsp; t is used as a switch, and yyyyyy is an offset. By 
choosing this value, and making this range adjacent to the NOT_FOUND marker, we save on switches. The following is a pseudocode sample of how this would work:
<div align="left">
  <pre>int getCE(...) {

  // get it out of buffer, if available
  if (ceBufferStart &lt; ceBufferEnd) {
    ce = *ceBufferStart;
    if (ceBufferStart == ceBufferEnd) {// reset!
      ceBufferStart = ceBufferEnd = ceBuffer;
  }

  // return if done
  if (source &gt;= sourceEnd) return EOS;

  // get character, and do simple mapping
  ch = *source++;
  if (ch &lt; 0xFF) {
    ce = tailoredData[ch]; // Latin1 is always here!
  } else {
    ce = tailoredData[tailoredIndex[(ch &gt;&gt;&gt; 8)] + (ch &amp; 0xFF)]; // trie
  }
  if (ce &gt;= NOT_FOUND) { // NOT_FOUND or SPECIAL
    if (ce &gt; NOT_FOUND) { // handle special casing
      getSpecialCE(tailoredSpecials, ...);
    }
    // if still not found, then try in the main table
    if (ce == NOT_FOUND) {
      ce = UcaData[UcaIndex[(ch &gt;&gt;&gt; 8)] + (ch &amp; 0xFF)]; // trie
      if (ce &gt; NOT_FOUND) {
        getSpecialCE(UcaSpecials, ...);
      }
      if (ce == NOT_FOUND) {
      // make artificial CE from codepoint, as in UCA
      }
    }
  }
  return ce;
}
const int NOT_FOUND = F0000000;</pre>
</div>
<blockquote>
  <p align="left"><b>Note: </b>NOT_FOUND is higher than all non-SPECIAL CEs, and less than all non-specials.</p>
  <p align="left"><b>Note: </b>every tailoring table is built to have <b><i>all</i></b> Latin1 characters, even when they are identical with the UCA table. That 
  way the Latin1 case is as fast as possible.</p>
</blockquote>
<h4 align="left"><a name="GetSpecialCE">GetSpecialCE</a></h4>
<p align="left">In the case that we do have specials, it falls into certain cases: Contraction, Expansion, Thai, Charset, and Surrogate. For processing these, 
we would do something like the following pseudocode:</p>
<div align="left">
  <pre>while (true)
  // special ce is has these fields: 
  // first nybble (4 bits) is F, next nybble (4 bits) is type
  int type = (ce &gt;&gt; 24) &amp; 0xF;
  // next 24 bits are data
  int data = ce &amp; 0x00FFFFFF; // remove F, type
  switch (type) {
    case NOT_FOUND_TAG: break;// never happens

    case THAI_TAG: // do Thai, Lao rearrangement
      ...
    case CONTRACTION_TAG: // do contraction thing
      ...
    case EXPANSION_TAG: // do expansion thing
      // put extra CEs into ceBuffer
      ... 
     case SURROGATE_TAG: // post 1.8
      //use offset, ch and *source to for trie with dataTable.extendedData
      ...
     case CHARSET_TAG: // (post 1.8)
      // do 
      ce = (ce &lt;&lt; 8) | 0x0303; // charsets only used for primary differences, so use middle 16 bits
      // the 0303 is to make a well-formed CE.
      charConverter[charSetNum].getOrdering(ch, ceBuffer, ceBufferTop);
      break;
  }
  if (ce &lt;= NOT_FOUND) break; // normal return
}</pre>
</div>
<h3 align="left">5.2 <a name="Expansion_Table">Expansion Table</a> (max size 2<sup>20</sup>)</h3>
<p align="left">The expansion table is simply a list of CEs. Internally it is broken into sections. The longer ones are null terminated: the others use an 
external length, based on the data from above.</p>
<table border="1" width="1%">
  <tr>
    <th width="100%">
      <p align="left">Expansions</p>
    </th>
  </tr>
  <tr>
    <td width="100%">
      <p align="left">CE</p>
    </td>
  </tr>
  <tr>
    <td width="100%">
      <p align="left">CE</p>
    </td>
  </tr>
  <tr>
    <td width="100%">
      <p align="left">CE</p>
    </td>
  </tr>
  <tr>
    <td width="100%">
      <p align="left">....</p>
    </td>
  </tr>
</table>
<p align="left">The data is broken into two pieces: 4 bits for length, 20 bits for offset. A length value of 0 means that the actual length didn't fit in 4 
bits, and the expansions are instead terminated by 00000000. Otherwise, the length is used to determine the number of CEs to add to the ceBuffer. E.g.</p>
<div align="left">
  <pre>len = ce &amp; 0xF;
offset = ce &gt;&gt; 8;
if (len == 0) // go until terminated
  ce = expansionTable[offset++]; // get first one. Never 0
  loop {
    item = ExpansionTable[offset++];
    if (item == 0) break;
    ceBuffer[ceBufferTop++] = item;
  }
} else {
  ce = expansionTable[offset++]; // get first one.
  for (int i = len-2; i &gt; 0; --i) {
    ceBuffer[ceBufferEnd++] = ExpansionTable[offset++];
  }
}</pre>
</div>
<table border="1" width="100%">
  <tr>
    <td width="100%" bgcolor="#FFFF66">
      <p align="left"><b><font color="#FF0000">Important: </font></b>when processing backwards (e.g. for French secondaries), expansion CEs have to be fed out 
      backwards as well. This is where the continuations are important: unlike the others they are <b><i>not</i></b> reversed. That is, if an expansion consists 
      of&nbsp; <code><b>A B B2 B3 C D</b></code> (where <code><b>B2</b></code> and <code><b>B3</b></code> are continuations), then the reversed order is <code><b>D 
      C B B2 B3 A</b></code>!</td>
  </tr>
</table>
<h3 align="left">5.3 <a name="Contraction Table">Contraction Table</a> (max size 2<sup>24</sup>)</h3>
<p align="left">The contraction tables consist of two parts, one 16 bits wide (uchars) and the other 32 bits wide (CEs). It uses two separate arrays instead of 
an array of structs to avoid alignment padding (this is also a <b>far</b> smaller footprint in the Java version!!). The first uchar in each section is actually 
a delta offset, not a uchar. It is to be added to the current position in the table to get to the real offset.</p>
<table border="0" cellspacing="0" cellpadding="4">
  <tr>
    <td width="25%" align="center" valign="top">
      <table border="1">
        <tr>
          <th width="100%" colspan="2">
            <p align="left">Contraction UChars</p>
          </th>
        </tr>
        <tr>
          <td width="100%" colspan="2">
            <p align="left">...</p>
          </td>
        </tr>
        <tr>
          <td width="100%" colspan="2">
            <p align="left">...</p>
          </td>
        </tr>
        <tr>
          <td width="50%">
            <p align="left">all-same</p>
          </td>
          <td width="50%">max-cc</td>
        </tr>
        <tr>
          <td width="100%" colspan="2">
            <p align="left">char_n1</p>
          </td>
        </tr>
        <tr>
          <td width="100%" colspan="2">
            <p align="left">char_n2</p>
          </td>
        </tr>
        <tr>
          <td width="100%" colspan="2">
            <p align="left">char_n3</p>
          </td>
        </tr>
        <tr>
          <td width="100%" colspan="2">
            <p align="left">FFFF</p>
          </td>
        </tr>
        <tr>
          <td width="100%" colspan="2">
            <p align="left">....</p>
          </td>
        </tr>
        <tr>
          <td width="50%">
            <p align="left">all-same</p>
          </td>
          <td width="50%">max-cc</td>
        </tr>
        <tr>
          <td width="100%" colspan="2">
            <p align="left">char_m1</p>
          </td>
        </tr>
        <tr>
          <td width="100%" colspan="2">
            <p align="left">char_m2</p>
          </td>
        </tr>
        <tr>
          <td width="100%" colspan="2">
            <p align="left">FFFF</p>
          </td>
        </tr>
        <tr>
          <td width="100%" colspan="2">
            <p align="left">...</p>
          </td>
        </tr>
      </table>
    </td>
    <td width="25%" align="center" valign="top">
      <table border="1">
        <tr>
          <th width="100%">
            <p align="left">Contraction Results</p>
          </th>
        </tr>
        <tr>
          <td width="100%">
            <p align="left">...</p>
          </td>
        </tr>
        <tr>
          <td width="100%">
            <p align="left">...</p>
          </td>
        </tr>
        <tr>
          <td width="100%">
            <p align="left">defaultCEn</p>
          </td>
        </tr>
        <tr>
          <td width="100%">
            <p align="left">CEn1</p>
          </td>
        </tr>
        <tr>
          <td width="100%">
            <p align="left">CEn2</p>
          </td>
        </tr>
        <tr>
          <td width="100%">
            <p align="left">CEn3</p>
          </td>
        </tr>
        <tr>
          <td width="100%">
            <p align="left">defaultCEn*</p>
          </td>
        </tr>
        <tr>
          <td width="100%">
            <p align="left">...</p>
          </td>
        </tr>
        <tr>
          <td width="100%">
            <p align="left">defaultCEm</p>
          </td>
        </tr>
        <tr>
          <td width="100%">
            <p align="left">CEm1</p>
          </td>
        </tr>
        <tr>
          <td width="100%">
            <p align="left">CEm2</p>
          </td>
        </tr>
        <tr>
          <td width="100%">
            <p align="left">defaultCEm</p>
          </td>
        </tr>
        <tr>
          <td width="100%">
            <p align="left">...</p>
          </td>
        </tr>
      </table>
    </td>
  </tr>
</table>
<p align="left">From the original CE, we use the data as an offset into the Contraction UChars table. If backwards is on (a programmatic setting for searching), 
we add the backwards offset delta to get a different backwards table, otherwise we advance one. We grab a character from the source. We search the characters 
(which are in sorted order). If a target char &gt;= source char, return the defaultCE (which may be expansion). If target char == source char, get the 
corresponding result. If that result is a contraction, grab another character, extract the offset, jump to the new section of the table and keep looping. 
Otherwise return that result (may be expansion).</p>
<p align="left">The first line of each of the subtables has a special meaning. The contraction uchars values split into two 8 bit values, and used for <a
href="#Discontiguous_Contractions">discontiguous contractions</a>.</p>
<ul>
  <li>
    <p align="left">max-cc: the maximum canonical combining class found in the table (8 bits).</li>
  <li>
    <p align="left">all-same: true (FF) if all of the <i>non-zero</i> canonical combining classes are identical.</li>
  <li>
    <p align="left">defaultCE: two different values
    <ul>
      <li>
        <p align="left">if the table is pointed to directly from the main data table, it is the CE we would have gotten if we had not had a contraction.</li>
      <li>
        <p align="left">otherwise, it is NOT_FOUND.</li>
    </ul>
  </li>
</ul>
<p align="left">We have to be careful of one special case. Suppose that JKL and KM are both contractions. When processing JKM, when we fail to find JKL, we need 
to be able to back up so that we can correctly return CE(J), CE(KM). When we hit NOT_FOUND, we unwind back to the first character, return the defaultCE for that 
case, and continue after it.</p>
<p align="left">Sample pseudo code:</p>
<div align="left">
  <pre>// only do backwards check first time. Cast to signed int delta if we are.
if (backwardsSearch) offset += contractionUChars[(int16_t)offset]; else ++offset;

// loop over multiple contractions
while (true) {
  if (source &gt;= sourceEnd) {
    contractionUChars[--offset]; // return default if end of string
    break;
  }
  uchar schar = source++;
  int startPosition = offset;
  uchar tchar;
  while (schar &gt; tchar = contractionUChars[offset++]); // loop til found or done
  if (schar != tchar) offset = startPosition - 1;      // use default if not found
  ce = contractionResult[offset];
  if (ce &lt; LOWEST_CONTRACTION) break;
  offset = ce &amp; 0x00FFFFFF;	// get new offset and keep looping
}

// we've broken out of the loop
if (ce &lt; LOWEST_EXPANSION) return ce;
else // do expansion thing</pre>
</div>
<p align="left">We know the inner loop terminates, since we always end each list of chars with FFFF. If the user happens to use a malformed string containing 
FFFF, we are still safe, since we store defaultCE in the corresponding result position.</p>
<h4 align="left"><a name="Discontiguous_Contractions">Discontiguous Contractions</a></h4>
<p align="left">There is a further complication for contraction. Suppose that a + ring is a contraction, sorted after z. As specified in UCA, adding additional 
marks, such as underdot, should not cause the a+ring to revert to sorting after 'a'. While in practice this does not occur often, it does happen in some 
languages. That means that just as in NFC, we have to handle cases of contraction <i>across</i> other combining marks. However, since this will be very rare, we 
do not want to degrade the normal performance because of it. Here are some sample cases for comparison, all supposing that a + ring is a contraction:</p>
<ol>
  <li>
    <p align="left">a + b</li>
  <li>
    <p align="left">a + ring + b</li>
  <li>
    <p align="left">a + underdot + b</li>
  <li>
    <p align="left">a + grave + b</li>
  <li>
    <p align="left">a + underdot + ring + b</li>
  <li>
    <p align="left">a + ring + grave + b</li>
</ol>
<p align="left">Case 1 and 2 are the ones to particularly focus on for performance. Here is how we do it. Since the input is normalized (either because we 
normalized to NFD, or because the user knows that the text is already FCD (see <a href="#CheckFCD">CheckFCD</a>), we know that any combining marks are in 
canonical order. We only have to worry about the ones that have non-zero combiningClass.</p>
<p align="left">If <i>all</i> of the following conditions are true for a character X (which has canonical combining class CCX), then we call a special routine.</p>
<ul>
  <li>
    <p align="left">max-cc is non-zero (indicating that there <i>is</i> a combining mark in the table that we might have to skip)</li>
  <li>
    <p align="left">CCX != 0 (since otherwise there can be no intervening combining marks)</li>
  <li>
    <p align="left">CCX &gt; max-cc (since if it were smaller, it would not be in normalized order -- if it were the same, it would be blocked).</li>
</ul>
<blockquote>
  <p align="left"><i><b>Note: </b>The special routine will be called so seldom that it does not have to be highly optimized!</i></p>
</blockquote>
<p align="left">It will do additional checks by looking ahead character-by-character to see if one matches the contraction table. It stops with a failure if any 
of the subsequent characters have a canonical combining Class of zero. If there is a match in the table, it checks to make sure that the previous character does 
not block the match (that happens if the previous character has the same combining class as the match). If the whole contraction matches, then special handling 
is invoked, since we have to (logically!) remove the intervening characters that were found! That is, suppose we have <i>pqrstu</i>, where <i>prt</i> is a 
discontiguous contraction. Then the result should be CE(<i>prt</i>), CE(<i>q</i>), CE(<i>s</i>), CE(<i>t</i>). That means that after prt is processed, we then 
have to process the characters that come between. </p>
<blockquote>
  <p align="left"><b>Note: </b>UCA only skips combining marks between elements of a contraction if they are trailing. It will not, for example, match a + b 
  against a + ring + b. One cannot simply match the a + b and act like the ring follows, since that would not distinguish it from a + b + ring. In those 
  instances, one would need an explicit contraction in the table for a + ring + b.</p>
</blockquote>
<h3 align="left">5.4 <a name="Thai">Thai</a></h3>
<p align="left">Certain Thai, Lao character rearrange (see UCA). In UCA if x is a Thai vowel, &quot;xyz&quot; should behave as if it were &quot;yxz&quot;. To 
avoid overhead of testing for character classes, we give all the rearranging characters a Special class. At the very beginning, we turn Thai processing ON.</p>
<p align="left">If Thai processing is ON, and we hit a Thai vowel, we backup by one source character, and copy the source buffer (if it is not our own private 
buffer) to a writable buffer. We then pass through all the remaining characters, and rearrange any Thai ones. We turn Thai processing OFF for the rest of the 
string, and return a zero CE (ignorable).</p>
<p align="left">When Thai processing is OFF, we use the data as an offset into the Expansion table. We fetch exactly 1 element, and process it (looking for 
specials, so it can be an expansion or contraction).</p>
<h3 align="left">5.5 <a name="Surrogates">Surrogates</a> (post 1.8)</h3>
<p align="left">Surrogates can be handled already using contractions, but this allows us the freedom to add an extra table for Unicode 3.1, when someone might 
want to add tens of thousands of surrogates. For such a case, we will have an optimized table. Essentially, what we do is add the following tables.</p>
<table border="0" cellspacing="0" cellpadding="4">
  <tr>
    <td width="25%" align="center" valign="top">
      <table border="1" width="1%">
        <tr>
          <th width="100%">
            <p align="left">Surrogate TrieยทIndex</p>
          </th>
        </tr>
        <tr>
          <td width="100%">
            <p align="left">index</p>
          </td>
        </tr>
        <tr>
          <td width="100%">
            <p align="left">index</p>
          </td>
        </tr>
        <tr>
          <td width="100%">
            <p align="left">...</p>
          </td>
        </tr>
      </table>
    </td>
    <td width="25%" align="center" valign="top">
      <table border="1" width="1%">
        <tr>
          <th width="100%">
            <p align="left">Surrogate TrieยทData</p>
          </th>
        </tr>
        <tr>
          <td width="100%">
            <p align="left">CE</p>
          </td>
        </tr>
        <tr>
          <td width="100%">
            <p align="left">CE</p>
          </td>
        </tr>
        <tr>
          <td width="100%">
            <p align="left">CE</p>
          </td>
        </tr>
        <tr>
          <td width="100%">
            <p align="left">CE</p>
          </td>
        </tr>
        <tr>
          <td width="100%">
            <p align="left">CE</p>
          </td>
        </tr>
        <tr>
          <td width="100%">
            <p align="left">CE</p>
          </td>
        </tr>
        <tr>
          <td width="100%">
            <p align="left">...</p>
          </td>
        </tr>
      </table>
    </td>
  </tr>
</table>
<p align="left">Fetch the next source character. If it is not a surrogate, backup, return a 0 CE (completely ignorable).</p>
<p align="left">Otherwise get the bottom 10 bits of that next source character. Perform the normal trie operations: take the top few bits and add them to data. 
Use that to lookup in the SurrogateTrieIndex, and find an offset. Add the bottom few bits to that, and use that to index into the SurrogateTrieData to get the 
CE.</p>
<p align="left">If that CE is an expansion or contraction, handle those cases, otherwise just return.</p>
<h3>5.6 <a name="Implicit_CEs">Implicit CEs</a></h3>
<p>If a character is not explicitly in the UCA table, then it is assigned an <i>implicit</i> CE which is generated from the code point. Implicit CEs are used 
for all characters that are not explicitly in the UCA table. Because of the way UCA is defined, these have to be in two groups, with different lead bytes. CJK 
Ideograph implicits are assigned with lead bytes from E8 to EB; other (including unassigned characters and Yi) are assigned with lead bytes from EC to EF.</p>
<blockquote>
  <p><b>Note: </b>Hangul implicit CEs are generated specially: see <a href="#Hangul_Implicit_CEs">Hangul Implicit CEs</a>!</p>
  <p><b>Note: </b>As per <a href="http://www.unicode.org/unicode/reports/tr10/#IllegalCodePoints">UCA 7.1.1 lllegal code points</a>, all values xxFFFE and 
  xxFFFF are ignored, as are all <b><i>unpaired</i></b> surrogates. The code to do this (after fetching the complete code point) is:</p>
  <blockquote>
    <pre>if ((codePoint &amp; 0xFFFE) == 0xFFFE || (0xD800 &lt;= codePoint &amp;&amp; codePoint &lt;= 0xDC00)) {
    return 0;  // illegal code value, use completely ignoreable!
}</pre>
  </blockquote>
</blockquote>
<p>In these generated CEs there is always a gap at least one (for possible later insertion), and with no zero bytes in the primaries. The implicit CEs use an 
optimized form that uses primary weights from Dxxx to EFFF. Basic code points (0000..FFFF) get a 24-bit primary weight, while supplementary code points 
(10000..10FFFF) get a 32 bit primary weight. Since the latter will be rare, this does not represent a performance issue.</p>
<blockquote>
  <p><b>Note: </b>These values are generated on the fly, not stored in the tables. They are <i>only</i> generated if there is no explicit table entry for the 
  code point!</p>
</blockquote>
<h4><a name="Basic_CP">Basic CP</a></h4>
<p>Distribute the bits as follows. The resulting primary uses 3 bytes in sort keys, and has a secondary and tertiary of 03 (UNMARKED).</p>
<pre>CP =                    xxxxyyyy yyyzzzzz</pre>
<pre>CE1 = 1101xxxx 1yyyyyyy 00000011 00000011 // normal</pre>
<pre>CE2 = zzzzz100 00000000 00000011 10000011 // continuation</pre>
<p>The primary gap is larger than one, which allows more elements to be inserted (in tailoring) without using extension CEs. Suppose that we have a Basic CP 
with qqqqq is zzzzz + 1; then here are the possible insertion values, marked with *. (The values at ** can be used iff qqqqq != 0.)</p>
<blockquote>
  <pre>zzzzz100
zzzzz101 *
zzzzz110 *
zzzzz111 *
qqqqq000 **
qqqqq001 **
qqqqq010 *
qqqqq011 *
qqqqq100</pre>
  <p><b>Note: </b>Hangul Syllables are handled specially. If normalization is on, they decompose to Jamo and are treated normally. If normalization is off, then 
  they fall through to the Implicit CE generation. The implicit CEs are generated as above, but then they are shifted to be in the Jamo range. This provides for 
  compatibility between normalized and unnormalized text.</p>
</blockquote>
<h4><a name="Supplementary_CP">Supplementary CP</a></h4>
<p>First subtract 10000 from CP, then distribute the 20 remaining bits as follows.&nbsp; The tertiary is UNMARKED. The resulting primary uses 3 bytes in sort 
keys.</p>
<pre>CP  =              wwww xxxxxxxy yyyyyyzz</pre>
<pre>CE1 = 1110wwww xxxxxxx1 00000011 00000011 // normal</pre>
<pre>CE2 = 1yyyyyyy zz100000 00000000 10000000 // continuation</pre>
<pre>CE1 = 0xE0010303 | (CP &amp; 0xFFE00) &lt;&lt; 8;</pre>
<pre>CE2 = 0x80200080 | (CP &amp; 0x001FF) &lt;&lt; 22;</pre>
<p>There's a large gap for customizing.</p>
<h4><a name="UCA_Comparison">UCA Comparison</a></h4>
<p>Except for CJK and Hangul, this results in sort keys that are 1 byte shorter per basic code point than what is described in UCA. The basic CJK and Hangul 
code points do take 1 byte longer per code point in sort keys than in UCA, but (a) UCA does not allow for tailoring relative to implicit code points without 
moving the code points, and (b) all of the CJK countries typically have explicit mappings for the characters they care about, which will reset them down to 2 
bytes in those cases.</p>
<h4><a name="Positioning_Implicit_CEs">Positioning Implicit CEs</a> (post 1.8)</h4>
<p>If there is a specific position set for <b>[undefined]</b> (see <a href="#Undefined_Positioning">rule syntax</a>), one that is not at the end of the file, 
then the weights are computed differently. The length of bytes required depends on the size of the gap where the Undefined items are positioned. For example, 
suppose there is a gap of only 1 where <b>[undefined]</b> is inserted, so that elements all start with a 16 bit primary pppppppp pppppppp. Here is how they 
would be generated:</p>
<h5>Basic CP</h5>
<p>With a gap of one, the resulting primary occupies 5 bytes in sort keys:</p>
<blockquote>
  <pre>codepoint = wwyyyyyy yzzzzzzz</pre>
  <pre>CE1 = pppppppp pppppppp UNMARKED UNMARKED</pre>
  <pre>CE2 = 111100ww 1yyyyyyy 1zzzzzzz 11110000</pre>
</blockquote>
<h5>Supplementary CP</h5>
<p>With a gap of one, the resulting primary occupies 6 bytes in sort keys. (again, subtracting 10000)</p>
<blockquote>
  <pre>codepoint = vvvw wwwwwwyy yyyyyzzz</pre>
  <pre>CE1 = pppppppp pppppppp UNMARKED UNMARKED</pre>
  <pre>CE2 = 11111vvv 1wwwwwww 1yyyyyyy 11110000</pre>
  <pre>CE3 = 1111zzz0 00000000 00000000 00000000</pre>
</blockquote>
<p>However, if the gap is at least 8 at the Undefined position, then effectively 3 bits from the first primary can be stolen, and all values would take 5 bytes 
in the sort key.</p>
<h4><a name="Hangul_Implicit_CEs">Hangul Implicit CEs</a></h4>
<p>Hangul Implicit CEs are handled specially. For everything but Hangul, our UCA table and Tailoring table generation guarantees that if you have FCD text, you 
get the same results if you turn off decomposition in the algorithm. (See <a href="#CheckFCD">CheckFCD</a>.) However, Hangul syllables still need to be 
decomposed. So if we do not normalize the text, then the Hangul Syllables will fall through to the Implicit CE phase. At that point, we will do a quick 
expansion, as in the following pseudocode.</p>
<blockquote>
  <p><b>Note: </b>The JamoSpecial flag in the following code comes from the tailoring table. See <a href="#Hangul_Building">Hangul Building</a> for more 
  information on how this is built in the UCA table and in the tailoring tables.</p>
</blockquote>
<pre>const int 
        SBase = 0xAC00, LBase = 0x1100, VBase = 0x1161, TBase = 0x11A7,
        LCount = 19, VCount = 21, TCount = 28,
        NCount = VCount * TCount,   // 588
        SCount = LCount * NCount,   // 11172
        LLimit = LBase + LCount,    // 1113
        VLimit = VBase + VCount,    // 1176
        TLimit = TBase + TCount,    // 11C3
        SLimit = SBase + SCount;    // D7A4

// once we have failed to find a match for codepoint cp, and are in the implicit code.
 
unsigned int L = cp - SCount;
if (cp &lt; SLimit) { // since it is unsigned, catchs zero case too

  // divide into pieces

  int T = L % TCount; // we do it in this order since some compilers can do % and / in one operation
  L /= TCount;
  int V = L % VCount;
  L /= VCount;

  // offset them

  L += LBase;
  V += VBase;
  T += TBase;

  // return the first CE, but first put the rest into the expansion buffer

  if (!context-&gt;JamoSpecial) { // FAST PATH
    pushOnExpansionBuffer(UCAMainTrie(V));
    if (T != TBase) {
        pushOnExpansionBuffer(UCAMainTrie(T));
    }
    return UCAMainTrie(L); // return first one

  } else { // Jamo is Special

    // do recursive processing of L, V, and T with fetchCE (but T only if not equal to TBase!!)

    bufferEnd = tempBuffer;
    *bufferEnd++ = L;
    *bufferEnd++ = V;
    if (T != TBase) {
      *bufferEnd++ = T;
    }
    return fetchCE(... tempBuffer, p, ...); // loops, stuffing remaining CEs into expansion buffer.
  }
}</pre>
<p>Note that because of this special processing of Hangul Syllables, we do not allow contractions between Hangul Syllables and other characters. That is, you 
can't have the contraction like:</p>
<p align="center">&amp; z &lt; ๊ฐx</p>
<h3 align="left">5.7 <a name="Charset_Ordering">Charset Ordering</a> (post 1.8)</h3>
<p align="left">To save space, we can use Charset Ordering. This is to account for the case where CJK characters are essentially just sorted in character set 
order, e.g. by JIS order. To do this, we would add functions to character set converters, as described in the API section.</p>
<h3 align="left">5.8 <a name="Script_Order">Script Order</a> (post 1.8)</h3>
<p align="left">ScriptOrder uses an optional array to reorder the top bytes of primary keys. A valid ScriptOrder array must map 00 to 00, and Fx to Fx, and 
variable primaries to variable primaries. Other bytes it is free to rearrange, but the result must be a permutation. This works by making sure that scripts do 
not share a first primary byte (see <a href="#UCA_Processing">#UCA Processing</a>).</p>
<blockquote>
  <p align="left"><b>Note: </b>Script Ordering is not applied in continuations.</p>
</blockquote>
<h2 align="left">7 <a name="Flat_File">Flat File</a></h2>
<p align="left">The flat file structure is very similar to what is describe in UCA, with extensions based upon the discussion here. Using a flat file allows us 
to dramatically decrease initialization time, and reduce memory consumption. When we process tailoring rules, we have an internal format that is very much like 
the UCA data. We will have a function that writes out that format into a flat file. Note that this is not an area where we will spend much time on performance, 
since 99% of the time this is done at ICU build time.</p>
<p align="left">When we build a tailoring, we make the following modifications to the current code. The current code builds an ordered list of tokens in the 
tailoring, where each token is an object containing the character(s), an indication of the strength difference, plus a special field for contracting characters. 
Once it is done, it assigns CEs to those characters based on the ordering and strength, putting the CE's into a trie table plus data structures for expanding, 
contracting, etc. Instead of this, we will build <i>multiple</i> lists, where each list is anchored to a position in the UCA.</p>
<p>We will also allow &quot;&amp; X &lt; Y&quot;, where X is <i>not</i> explicitly defined. (In ICU 1.6 and previous, this is disallowed). In that case, Y will 
give a value that is based off of the <i>implicit</i> value that X would have. In processing the rules in the implementation, we may give X the implicit value 
in the intermediate data structure, then remove it when we finally store into the flat file to save space.</p>
<p align="left">Since we are tailoring the UCA, we could have call to insert elements <i>before</i> a given UCA element. Currently, that would have to be done 
by finding the previous element in the table, and inserting after. That is, to insert x with a primary difference before 'a', we have to know that '9'' is 
before it in the UCA, and say &amp;'9' &lt; x.&nbsp; However, this isn't very robust, so we add extra syntax for it. See <a href="#Rule Syntax">Rule Syntax</a>.</p>
<p align="left">Once the tailoring table is completely built, we will add any UCA characters in the range 0..FF that are not there already. At a slight increase 
in table size, that guarantees the minimal code path for many cases. We will also close the file under canonical decomposition, so that turning off 
decomposition can be done for performance (in some cases). We will close the file under compatibility decomposition, so that when you tailor a letter, the 
compatibility characters containing it are also moved. E.g. if we put &amp; z &lt; i, then the &quot;fi&quot; ligature will then sort after &quot;fz&quot;.</p>
<h4 align="left"><a name="Hangul_Building">Hangul Building</a></h4>
<p>We set JamoTailored in the UCA table structure to true if any of the characters (U+1100..U+1112, U+1161..U+1175, U+11A8..U+11C2) are contractions or 
expansions. JamoSpecial in the tailoring tables is set to true iff JamoSpecial is set in UCA OR any of those characters are tailored in the tailoring rules. 99% 
of the time, the Jamo will not be special, and we can just get the values directly from the UCA Main Trie table. Only if the Jamo are special do we have to use 
the more expensive lookup.</p>
<h3 align="left"><b>6.1 <a name="Postpone_Insertion">Postpone Insertion</a></b></h3>
<p align="left">ICU 1.6 and below used <i>direct insertion</i> for tailoring, as shown below. ICU 1.8 uses <i>postpone insertion</i>, as shown below. With 
postpone insertion, rules</p>
<div align="center">
  <center>
  <table border="1" cellspacing="1" cellpadding="4">
    <tr>
      <th>&nbsp;</th>
      <th>Source</th>
      <th>Result</th>
    </tr>
    <tr>
      <th>UCA</th>
      <td><b>...&nbsp; x &lt;&lt;&lt; X &lt;&lt; x' &lt;&lt;&lt; X' &lt; y ...</b></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <th>Direct Insertion</th>
      <td><font color="#FF0000"><b>&amp; x &lt; z</b></font></td>
      <td><b>...&nbsp; x <font color="#FF0000">&lt; z</font> &lt;&lt;&lt; X &lt;&lt; x' &lt;&lt;&lt; X'&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt; y</b></td>
    </tr>
    <tr>
      <th>Postpone Insertion</th>
      <td><font color="#FF0000"><b>&amp; x &lt; z</b></font></td>
      <td><b>...&nbsp; x&nbsp;&nbsp;&nbsp;&nbsp; &lt;&lt;&lt; X &lt;&lt; x' &lt;&lt;&lt; X' <font color="#FF0000">&lt; z</font> &lt; y</b></td>
    </tr>
  </table>
  </center>
</div>
<p align="left">The reason we didn't originally use postpone is that it is relatively easy to emulate. For example, in the above case, <b><font color="#FF0000">&amp; 
X' &lt; z</font></b>&nbsp; with direct insertion is the equivalent of <font color="#FF0000"><b>&amp; x &lt; z</b></font> with postpone insertion. However, it is 
not easy to emulate direct insertion with postpone insertion: in the above case you would have to use <font color="#FF0000"><b>&amp; x &lt; z &lt;&lt;&lt; X 
&lt;&lt; x' &lt;&lt;&lt; X'</b></font> to emulate <b><font color="#FF0000">&amp;x &lt; z</font></b>. However, postpone insertion is probably more intuitive, is 
more stable under new versions of UCA, and works better with the large number of variant characters in UCA. In practice, given the tailoring rules from the old 
ICU, this will actually produce results that more compatible than if we retained direct insertion.</p>
<h3 align="left">6.2 <a name="Rule_Storage">Rule Storage</a></h3>
<p align="left">The API for get rules will return just the tailoring rules (we store this with the flat file). The API for get full rules will get the UCA rules 
(we generate and store this with the UCA flat file), then appends the tailoring rules.</p>
<h3>6.3 <a name="Details_on_Generation">Details on Generation</a></h3>
<p>The following describes the CE generation process in more detail. In all of the following discussion:</p>
<ul>
  <li>the relations , and ; are converted into &lt;&lt;&lt; and &lt;&lt;.</li>
  <li>* stands for any of the relations =, &lt;, &lt;&lt;, &lt;&lt;&lt;, &gt;, &gt;&gt;, &gt;&gt;&gt;.</li>
  <li>The <i>polarity</i> for &lt;, &lt;&lt;, &lt;&lt;&lt; and = is POSITIVE, for &gt;, &gt;&gt;, &gt;&gt;&gt; is NEGATIVE.</li>
  <li>The operations of &lt;, &gt; are stronger than &lt;&lt;, &gt;&gt;, which are strong than &lt;&lt;&lt;, &gt;&gt;&gt;, which are stronger than =.</li>
  <li>
    <p><i>For now, the discussion will only cover the positive directions, since we are only doing that in 1.8.</i></p>
  </li>
</ul>
<p>We will generate the following internal structures. (The CEtoStr is generated from the UCA, and stored in a flat file).</p>
<h4><a name="Tailoring_Structures">Tailoring Structures</a></h4>
<div align="center">
  <center>
  <table border="0" cellspacing="0" cellpadding="4">
    <tr>
      <td width="25%" align="center" valign="top">
        <table border="1">
          <caption><b>ListList</b></caption>
          <tr>
            <td width="100%">ListHeader0</td>
          </tr>
          <tr>
            <td width="100%">ListHeader1</td>
          </tr>
          <tr>
            <td width="100%">ListHeader2</td>
          </tr>
          <tr>
            <td width="100%">...</td>
          </tr>
          <tr>
            <td width="100%">...</td>
          </tr>
          <tr>
            <td width="100%">&nbsp;...</td>
          </tr>
        </table>
      </td>
      <td width="25%" align="center" valign="top">
        <table border="1">
          <caption><b>ListHeader</b></caption>
          <tr>
            <td width="100%">Token* firstPositive</td>
          </tr>
          <tr>
            <td width="100%">Token* lastPositive</td>
          </tr>
          <tr>
            <td width="100%">Token* firstNegative</td>
          </tr>
          <tr>
            <td width="100%">Token* lastNegative</td>
          </tr>
          <tr>
            <td width="100%">Token* reset</td>
          </tr>
          <tr>
            <td width="100%">CE baseCE</td>
          </tr>
          <tr>
            <td width="100%">CE nextCE</td>
          </tr>
          <tr>
            <td width="100%">CE previousCE</td>
          </tr>
          <tr>
            <td width="100%">Strength strongestP</td>
          </tr>
          <tr>
            <td width="100%">Strength strongestN</td>
          </tr>
        </table>
      </td>
      <td width="25%" align="center" valign="top">
        <table border="1">
          <caption><b>Token</b></caption>
          <tr>
            <td width="100%">Token* previous</td>
          </tr>
          <tr>
            <td width="100%">Token* next</td>
          </tr>
          <tr>
            <td width="100%">StrRep source</td>
          </tr>
          <tr>
            <td width="100%">StrRep expansion</td>
          </tr>
          <tr>
            <td width="100%">Strength strength</td>
          </tr>
          <tr>
            <td width="100%">Polarity polarity</td>
          </tr>
          <tr>
            <td width="100%">Count1</td>
          </tr>
          <tr>
            <td width="100%">Count2</td>
          </tr>
          <tr>
            <td width="100%">Count3</td>
          </tr>
        </table>
        &nbsp;
        <table border="1">
          <caption><b>CharsToken</b></caption>
          <tr>
            <td width="100%">Hashtable for mapping<br>
              from chars to tokens</td>
          </tr>
        </table>
      </td>
      <td width="25%" align="center" valign="top">
        <table border="1">
          <caption><b>CEtoStr</b></caption>
          <tr>
            <td width="50%" colspan="2">fast binary header</td>
          </tr>
          <tr>
            <td width="25%">CE0a</td>
            <td width="25%">CE0b</td>
            <td width="25%">StrCRep</td>
          </tr>
          <tr>
            <td width="25%">CE1a</td>
            <td width="25%">CE1b</td>
            <td width="25%">StrCRep</td>
          </tr>
          <tr>
            <td width="25%">...</td>
            <td width="25%">...</td>
            <td width="25%">...</td>
          </tr>
          <tr>
            <td width="25%">CEna</td>
            <td width="25%">CEnb</td>
            <td width="25%">StrCRep</td>
          </tr>
        </table>
        &nbsp;
        <table border="1">
          <caption><b>StringContinue</b></caption>
          <tr>
            <td width="50%">uChar[x]</td>
          </tr>
        </table>
    </tr>
    <tr>
      <td width="25%" align="left" valign="top"><i>list of list of tokens</i></td>
      <td width="25%" align="left" valign="top"><i>header for token list</i></td>
      <td width="25%" align="left" valign="top"><i>tokens,<br>
        mapping to chars</i></td>
      <td width="25%" align="left" valign="top"><i>mapping to:<br>
        next, previous CEs, characters between CEs</i>
    </tr>
  </table>
  </center>
</div>
<p><b>Notes:</b></p>
<ul>
  <li><b>StrRep</b> is an int. Top 8 bits are length, bottom 24 bits are an offset into the <b>Rules</b> string. This saves string allocations. If the string 
    contains quotes, then we copy an unquoted version at the bottom of the Rules string for references.</li>
  <li><b>CEtoStr</b>
    <ul>
      <li>This is a table used only for generating Tailoring tables, and is so kept separate from the UCA. It consists of all the FCEs in the UCA in sorted 
        order, in the following format:</li>
      <li>
        <p align="left">Each FCE is stored as two Unflagged CEs, a and b. If there is no need for a continuation, CEb is zero. We add two terminating elements, 
        the lowest possible CE and greatest possible CE at the start and end of the table to ensure we have bracketing values. To find next and previous, we 
        take baseCE, and binary search for it in this table. There is a fast binary header, supporting completely unrolled binary search.</li>
      <li>
        <p align="left">StrCRep is either a codepoint, or if the top byte is non-zero, is a StrRep pointing into StringContinue. If one CE corresponds to two 
        character strings, both are listed in StringContinue, separated by FFFF. If a string has an expansion, that uses FFFE as a delimiter. Example:
        <ul>
          <li>
            <p align="left">CE_Reverse</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<p><b><a name="Building_Tokens">Building Tokens</a></b></p>
<ol>
  <li>Build a ListList. Each list has a header, which contains two lists (positive and negative), a reset token, a baseCE, nextCE, and previousCE. The lists and 
    reset may be null.</li>
  <li>As you process, you keep a LAST pointer that points to the last token you handled.</li>
  <li>Consider each item: relation, source, and expansion: e.g. ...<u>&lt; x / y</u> ...
    <ul>
      <li>First convert all expansions into normal form. Examples:
        <ul>
          <li>If &quot;xy&quot; doesn't occur earlier in the list or in the UCA, convert &amp;xy * c * d * ... into &amp;x * c/y * d * ...</li>
          <li>Note: reset values can <i>never have</i> expansions, although they can cause the very next item to have one. They may be contractions, if they are 
            found earlier in the list.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Lookup each [source,&nbsp; expansion] in the CharsToToken map, and find a sourceToken</li>
  <li>If the relation is a reset:
    <ul>
      <li>If sourceToken is null
        <ul>
          <li>Create new list, create new sourceToken, make the baseCE from source, put the sourceToken in ListHeader of the new list</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Otherwise (when relation != reset)
    <ul>
      <li>If sourceToken is null, create new one, otherwise remove sourceToken from where it was.</li>
      <li>If LAST is a reset
        <ul>
          <li>insert sourceToken at the head of either the positive list or the negative list, depending on the polarity of relation.</li>
          <li>set the polarity of sourceToken to be the same as the list you put it in.</li>
        </ul>
      </li>
      <li>Otherwise (when LAST is not a reset)
        <ul>
          <li>if polarity (LAST) == polarity(relation), insert sourceToken <b>after</b> LAST, otherwise insert <b>before</b>.</li>
          <li>when inserting after or before, search to the next position with the same strength in that direction. (This is called <a
            href="#Postpone_Insertion">postpone insertion</a>).</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>After all this, set LAST to point to sourceToken, and goto step 3.</li>
</ol>
<p>At the end of this process, we will end up with a list of lists of tokens.&nbsp;</p>
<h4><a name="Canonical_Closure">Canonical Closure</a></h4>
<p>We will then close the sets of tokens with the canonical closure and Latin-1 characters,</p>
<ul>
  <li>For each Unicode character C with a canonical decomposition (e.g. รฅ), check to see the CEs resulting from the canonical decomposition of C (e.g. a, ยฐ) 
    would be the same in the tailoring as what UCA returns from C. If not, then the appropriate expansion is added (e.g. รฅ = a ยฐ) to the tailoring.
    <ul>
      <li><b>Note: </b>The UCA already contains closures for the non-tailored items.</li>
      <li><b>Note:</b> This is not recursive; it takes a single pass through just those characters with canonical decompositions.</li>
    </ul>
  </li>
  <li><b>(Post 1.8) </b>For each Unicode character with a compatibility decomposition (e.g. circled-a), check to see the CEs resulting from the canonical 
    decomposition&nbsp; (a, ยฐ) would be the same in the tailoring as they were in the UCA. If not, then the appropriate expansion is added (circled-a = a) to 
    the tailoring, but with the tertiary value being set according to the table in UCA.
    <ul>
      <li>This is postponed until after 1.8, since the tertiary values are not easily computable.</li>
    </ul>
  </li>
  <li>Copy all the UCA mappings for Latin-1 characters that are not tailored into the tailoring. This also does not require any gap processing.
    <ul>
      <li>The goal is performance, as described above.</li>
    </ul>
  </li>
</ul>
<h4><a name="Assigning_CEs">Assigning CEs</a></h4>
<p>To do the next phase, we need the following CEs from the Base Collation Element:</p>
<blockquote>
  <p align="left"><b>[13 . 06 . 09]&nbsp; &lt;= BCE<br>
  </b>...<br>
  [13 . 06 . 09] &lt;= nextCELow3<br>
  [13 . 06 . 0B] &lt;= nextCEHigh3<br>
  ...<br>
  [13 . 06 . 1F] &lt;= nextCELow2<br>
  [13 . 07 . 03] &lt;= nextCEHigh2<br>
  ...<br>
  [13 . 0B . 03] &lt;= nextCELow1<br>
  [15 . 03 . 04] &lt;= nextCEHigh1
</blockquote>
<p align="left">These are determined as follows from the CEtoStr table.
<ul>
  <li>
    <p align="left">From BCE, find the first subsequent CE that is tertiary-greater. That becomes nextCEHigh3. nextCELow3 is simply the CE immediately before 
    nextCEHigh3.</li>
  <li>
    <p align="left">...</li>
  <li>
    <p align="left">From BCE, find the first subsequent CE that is primary-greater. That becomes nextCEHigh1. nextCELow1 is simply the CE immediately before 
    nextCEHigh1.</li>
  <li>
    <p align="left">From BCE, find the first previous CE that is tertiary-less. That becomes previousCELow1. previousCEHigh1 is simply the CE immediately after 
    previousCELow1.</li>
  <li>
    <p align="left">...</li>
</ul>
<p align="left">Note that ranges may be identical. Thus nextCEHigh1 might be the same as nextCEHigh2. Since nextCELow is determined by nextCEHigh, if the High's 
are the same than the Low's are the same.</p>
<ol>
  <li>Suppose we have BCE &lt;&lt;&lt; x &lt;&lt;&lt; y &lt;&lt; z &lt;&lt;&lt; w &lt;&lt; u &lt; r &lt;&lt;&lt; s ...</li>
  <li>We will insert &quot;&lt;&lt;&lt; x &lt;&lt;&lt; y&quot; between nextCELow3 and nextCEHigh3</li>
  <li>We will insert &quot;&lt;&lt; z &lt;&lt;&lt; w &lt;&lt; u&quot; between nextCELow2 and nextCEHigh2</li>
  <li>We will insert &quot;&lt; r &lt;&lt;&lt; s ...&quot; (everything else) between nexCELow1 and nextCEHigh1</li>
  <li>At each point, the key values are the number of weights <i>at that level</i>, and the bounds. For example, for #3 we have 2 secondary weights to squeeze 
    in.</li>
</ol>
<p>If the ranges overlap, then all the items are inserted at the higher level. Thus if nextCEHigh2 == nextCEHigh3, then we insert &quot;&lt;&lt;&lt; x 
&lt;&lt;&lt; y &lt;&lt; z &lt;&lt;&lt; w &lt;&lt; u&quot; between nextCELow2 and nextCEHigh2. There are still only 2 key values.</p>
<p>How do we find the number of items to squeeze in at each level? We fill in the CountN fields in each token, working backwards. Any time we go up a to a 
higher (i.e., lower numbered) level, we reset the lower counters to 1. Here is an example of a series of tokens, and their levels and counters after we have 
done this process. (We omit the identical cases to make the diagram simpler).</p>
<table border="1">
  <tr>
    <th>L1</th>
    <td colspan="7">&nbsp;</td>
    <td>9</td>
    <td>8</td>
    <td>7</td>
    <td colspan="2">&nbsp;</td>
    <td>6</td>
    <td>5</td>
    <td colspan="8">&nbsp;</td>
    <td>4</td>
    <td>3</td>
    <td>2</td>
    <td colspan="3">&nbsp;</td>
    <td>1</td>
    <td colspan="2">&nbsp;</td>
  </tr>
  <tr>
    <th>L2</th>
    <td colspan="3">&nbsp;</td>
    <td>4</td>
    <td>3</td>
    <td>2</td>
    <td>1</td>
    <td colspan="3">&nbsp;</td>
    <td>2</td>
    <td>1</td>
    <td colspan="2">&nbsp;</td>
    <td>5</td>
    <td>4</td>
    <td>3</td>
    <td>&nbsp;</td>
    <td>2</td>
    <td colspan="2">&nbsp;</td>
    <td>1</td>
    <td colspan="3">&nbsp;</td>
    <td>3</td>
    <td>2</td>
    <td>1</td>
    <td colspan="3">&nbsp;</td>
  </tr>
  <tr>
    <th>L3</th>
    <td>3</td>
    <td>2</td>
    <td>1</td>
    <td colspan="14">&nbsp;</td>
    <td>1</td>
    <td>&nbsp;</td>
    <td>2</td>
    <td>1</td>
    <td colspan="8">&nbsp;</td>
    <td>2</td>
    <td>1</td>
  </tr>
  <tr>
    <th>&nbsp;</th>
    <th colspan="3">A</th>
    <th colspan="4">B</th>
    <th colspan="24">C</th>
  </tr>
</table>
<p>We now know at each item how many remaining items of the same weight there are. And we know the bounds: we put the A items between nextCELow3 and 
nextCEHigh3, the B items between nextCELow2 and nextCEHigh2, and the C items nexCELow1 and nextCEHigh1. For any items in C at levels 2 or greater, or any items 
at B of level 3, the bounds are for those levels are 02..FF.</p>
<p>To aid in the production, we have three weight generators. A weight generator handles the complications of figuring out the optimal weights as in <a
href="#Intermediate_CEs">Intermediate CEs</a> below. When we reset a weight generator, we tell it the low and high bounds for the weights, and the number of 
items. It will then feed out nextWeight values successively.</p>
<p>As we pass through the tokens from start to end, we look at the current token and the one after it (if any). Based on that, we reset the weight generators if 
we are about to go down in level. We then ask the three weight generators for the weights for each level of the current token.</p>
<h4><a name="Intermediate_CEs">Intermediate CEs</a></h4>
<p class="a" align="left">How do we determine how to allocate a number of weights, given a lower and upper bound?</p>
<p class="a" align="left">First, normalize the bounds to 32 bits, left shifted. Then determine the following counts (using an example):</p>
<table border="1" width="100%">
  <tr>
    <td width="33%" bgcolor="#FFFF66">lowBounds</td>
    <td width="33%" bgcolor="#FFFF66">36.42.15.00</td>
    <td width="34%" bgcolor="#FFFF66">&nbsp;</td>
  </tr>
  <tr>
    <td width="33%">firstLow</td>
    <td width="33%">36.42.16.00</td>
    <td width="34%" rowspan="2">lowCount = FF - 16 + 1</td>
  </tr>
  <tr>
    <td width="33%">lastLow</td>
    <td width="33%">36.42.FF.00</td>
  </tr>
  <tr>
    <td width="33%">firstMid</td>
    <td width="33%">36.43.00.00</td>
    <td width="34%" rowspan="2">midCount = 59 - 43 + 1</td>
  </tr>
  <tr>
    <td width="33%">lastMid</td>
    <td width="33%">36.59.00.00</td>
  </tr>
  <tr>
    <td width="33%">firstHigh</td>
    <td width="33%">36.5A.02.00</td>
    <td width="34%" rowspan="2">highCount = 08 - 06 + 1</td>
  </tr>
  <tr>
    <td width="33%">lastHigh</td>
    <td width="33%">36.5A.06.00</td>
  </tr>
  <tr>
    <td width="33%" bgcolor="#FFFF66">highBounds</td>
    <td width="33%" bgcolor="#FFFF66">36.5A.08.00</td>
    <td width="34%" bgcolor="#FFFF66">&nbsp;</td>
  </tr>
</table>
<p class="a" align="left">Either low or mid may not exist (e.g. if lowBounds and highBounds are the same length, and have the same non-final bytes. Because of 
the way we construct the UCA, we are guaranteed that highCount is at least 1.</p>
<blockquote>
  <b>Note: When incrementing primary values, we will not cross high byte boundaries except where there is only a single-byte primary. That is to ensure that the 
  <i>script reordering</i> will continue to work. If such a boundary falls in the middle of first, mid or last, then truncate it (choosing the longer range).</b>
</blockquote>
<p class="a" align="left">Set slot = low, mid, or high depending on which has fewer bytes (and exists). If slotCount is large enough for targetCount, then 
allocate the values there.</p>
<p class="a" align="left">Otherwise, loop, adding 1 to slotLen, and multiplying slotCount by 254 (the number of allowable bytes, since 00 and 01 can't be used. 
Continue until slotCount &gt;= targetCount. Then find out how many values can be done with one fewer bytes:</p>
<blockquote>
  <p class="a" align="left">shorterCount = floor((slotCount - targetCount)/254)</p>
  <p class="a" align="left">slotCount -= shorterCount.</p>
</blockquote>
<p class="a" align="left">Once we have this, allocate shorterCount items within slot with each item having a byte length of (slotLen - 1), then the remainder of 
the items with byte lengths of slotLen. Example: suppose we have 7 items, to squeeze into a gap of 5 with a length of 2. Then we can fit 4 in with 2 bytes, and 
the remaining 3 items will take 3 bytes.</p>
<blockquote>
  <p class="a" align="left"><b>Note: while it is possible to produce slightly more optimal weightings, we won't spend the time necessary to compute them.</b></p>
</blockquote>
<h4 align="left"><b><a name="Assigning_Expansions">Assigning Expansions</a></b></h4>
<p align="left">After we have assigned all of the CEs for the source parts of the tokens, we make a second pass through and find the list of CEs for all 
expansions. We do this in two passes since &quot;a/e&quot; will depend on the final CE value for &quot;e&quot;, which may be changed by an element after it.</p>
<h4 align="left"><a name="Tailoring_Case_Bit">Tailoring Case Bit</a></h4>
<p align="left">Since the case bit in CEs is character based, it does not depend on the tailoring rules at all. It is basically a post-processing step. That is, 
in any tailoring rule that results in &quot;xyz&quot; beings given collation elements C1, C2...Cn, each of the characters x, y, and z are checked by looking 
them up in the UCA table. If any one of them has a first CE that has the case bit on, then the case bit is turned on in C1..Cn.</p>
<h2 align="left">8 <a name="UCA_Processing">UCA Processing</a></h2>
<p align="left">The UCA data table only specifies relative ordering among weights. We are free to redistribute the weight values as long as the relative 
ordering is the same. To make our processing more efficient, decrease the sort-key length for A-Z, allow script-ordering, provide for tailoring of the read-only 
table, we will preprocess the data so that we:</p>
<ol>
  <li>
    <p align="left">Add gap of at least 1 between all weights at each level (allows tailoring).</li>
  <li>
    <p align="left">Allow no bytes of 00, 01, 02. See <a href="#Magic_Bytes">Magic Bytes</a>.</li>
  <li>
    <p align="left">Set the following primaries to have odd single-byte primaries (e.g. 3100, 3300, 3500...) for compression (they are odd to allow gaps for 
    tailoring).
    <ol>
      <li>
        <p align="left">Space</li>
      <li>
        <p align="left">Latin a-z</li>
    </ol>
  </li>
  <li>
    <p align="left">Start at 04 for all weights. See <a href="#Magic_Bytes">Magic Bytes</a>.</li>
  <li>
    <p align="left">For secondaries and tertiaries, have a large gap between UNMARKED and other values, to allow for UCA-style run-length compression.</li>
  <li>
    <p align="left">Leave gaps at the start and end of each byte range, to allow for tailoring and future UCA values.</li>
  <li>
    <p align="left">Make sure that all primaries are less than [top].&nbsp; See <a href="#Magic_Bytes">Magic Bytes</a>.</li>
  <li>
    <p align="left">Drop all &quot;artificial secondaries&quot; introduced for canonical decomposables, then pack secondaries, starting at UNMARKED. (so we can 
    use fewer bits for secondaries)</li>
  <li>
    <p align="left">Start different scripts on 256 bounds (to let us shuffle scripts). Scripts are determined by the scripts of letters in ScriptNames.txt, 
    except that&nbsp; variables are treated as a separate script.</li>
  <li>
    <p align="left">We generate the case bit, as described below.</li>
  <li>
    <p align="left">As in Tailoring, we form the canonical closure of the table. That is, if a character X has a canonical decomposition Y, then we add the 
    mapping from X to the CEs that correspond to the characters in Y. This allows us to accept all FCD characters without normalization processing (See <a
    href="#CheckFCD">CheckFCD</a>).</li>
</ol>
<div align="center">
  <center>
  <table border="1" width="90%">
    <tr>
      <td width="100%">
        <p align="left"><b>Note: </b>We <i>already</i> allow for both normalized and non-normalized collation in ICU 1.6 (and earlier). In building data tables: 
        (a) all rules are normalized to NFD before the characters are added to the table, (b) after all rules have been added, then all decomposables (except 
        Hangul) are added as expansions. Step (b) is equivalent to adding all the following rules (with normalization off):</p>
        <blockquote>
          <p align="left">&amp; a ` = ร<br>
          &amp; a <font size="3">ยด = รก<br>
          ...</font></p>
        </blockquote>
        <p align="left"><font size="3">This will get the correct answer whether or not the source text for any sort key is normalized or not, <i>unless</i> the 
        text contains characters that are not in canonical order. So for the locales that would really be affected by this (Greece, Vietnam), we turn on 
        normalization by default.</font></td>
    </tr>
  </table>
  </center>
</div>
<p align="left"><i><b>A draft processed UCA table is found in <a href="#Appendix_3">Appendix 3: Data Files</a>. For information on the fractional_ce, see <a
href="#Fractional_Collation_Elements">Fractional Collation Elements</a>.</b></i></p>
<p align="left">Once we process the UCA data, we write it out in a compact, efficient form using the function described in <a href="#Flat_File">Flat File</a>.</p>
<h3 align="left"><a name="UCA_Case_Bit">UCA Case Bit</a>s</h3>
<p align="left">Here is sample code for computing the case bits. Once this is in the UCA, then that very data is used in tailorings: see <a
href="#Tailoring_Case_Bit">Tailoring Case Bit</a>.</p>
<div align="left">
  <pre align="left">static final boolean needsCaseBit(String x) {
        String s = NFKD.normalize(x);
        if (!ucd.getCase(s, FULL, LOWER).equals(s)) return true;
        if (!toSmallKana(s).equals(s)) return true;
        return false;
    }
    
    static final StringBuffer toSmallKanaBuffer = new StringBuffer();
    
    static final String toSmallKana(String s) {
        // note: don't need to do surrogates; none exist
        boolean gotOne = false;
        toSmallKanaBuffer.setLength(0);
        for (int i = 0; i &lt; s.length(); ++i) {
            char c = s.charAt(i);
            if ('\u3042' &lt;= c &amp;&amp; c &lt;= '\u30EF') {
                switch(c - 0x3000) {
                  case 0x42: case 0x44: case 0x46: case 0x48: case 0x4A: case 0x64: case 0x84: case 0x86: case 0x8F:
                  case 0xA2: case 0xA4: case 0xA6: case 0xA8: case 0xAA: case 0xC4: case 0xE4: case 0xE6: case 0xEF:
                    --c; // maps to previous char
                    gotOne = true;
                    break;
                  case 0xAB:
                    c = '\u30F5'; 
                    gotOne = true;
                    break;
                  case 0xB1:
                    c = '\u30F6'; 
                    gotOne = true;
                    break;
                }
            }
            toSmallKanaBuffer.append(c);
        }
        if (gotOne) return toSmallKanaBuffer.toString();
        return s;
    }
</pre>
</div>
<h2 align="left">8 <a name="Rule_Syntax">Rule Syntax</a></h2>
<p align="left">Readers should be familiar with the current ICU syntax (also used in Java) before proceeding.</p>
<ul>
  <li><a href="http://oss.software.ibm.com/icu/apiref/class_RuleBasedCollator.html#_details">Current ICU Collation Rule Syntax</a></li>
  <li><a href="http://java.sun.com/j2se/1.3/docs/api/java/text/RuleBasedCollator.html">http://java.sun.com/j2se/1.3/docs/api/java/text/RuleBasedCollator.html</a></li>
</ul>
<p align="left">The rule syntax will be augmented slightly to allow control of UCA features, and some of the additional features discussed here.&nbsp;</p>
<p align="left">In the following, additional commands are expressed in square brackets. Extra white space in rules is not significant, except where it would 
break identifiers. Case in keywords is not significant. For forward compatibility, unknown keywords are ignored.</p>
<blockquote>
  <p align="left"><b>Note: </b>all ASCII characters except a-z, A-Z, 0-9 are reserved for syntax characters. They must be quoted (with ') if they are used as 
  characters. The single quote character ' must be represented by ''. All control characters and space must also be quoted.</p>
  <p align="left"><b>Note: </b>in all enumerated parameters, a &quot;default&quot; parameter is allowed, one that will simply pick up what is in the UCA. 
  Similarly, in the API a &quot;default&quot; parameter is always allowed, that picks up what is in the Tailoring (or if not modified in the Tailoring, what is 
  in the UCA).</p>
</blockquote>
<h3 align="left"><a name="Semantic_Changes">Semantic Changes</a></h3>
<p align="left">We are changing the semantics to be <a href="#Postpone_Insertion">Postpone Insertion</a>. In addition, we have altered the semantics of 
extension. Before,</p>
<div align="left">
  <pre align="left">&amp; pq &lt; r &lt; s &lt; t</pre>
</div>
<p align="left">was equivalent to:</p>
<div align="left">
  <pre align="left">&amp; p &lt; r/q &lt; s &lt; t</pre>
</div>
<p align="left">Now, the expansion propagates to all remaining rules (up to the next reset), so it is equivalent to:</p>
<div align="left">
  <pre align="left">&amp; p &lt; r/q &lt; s/q &lt; t/q</pre>
</div>
<p align="left">This yields more intuitive results, especially when the character after the reset is decomposable. Since all rules are converted to NFD before 
they are interpreted, this may result in contractions that the rule-writer is not aware of.</p>
<h3 align="left">Ordering Syntax</h3>
<p align="left">We add x &lt; y, x &lt;&lt; y, x &lt;&lt;&lt; y syntax. This is simpler to remember, and will allow us in the future to have the corresponding x 
&gt; y, etc. </p>
<h3 align="left">UCA Options</h3>
<div align="left">
  <pre>[alternate shifted]
[backwards 2]
[variable top]
[top]</pre>
</div>
<ul>
  <li>
    <p align="left">For alternate we only support 'non-ignorable' | 'shifted'.</li>
  <li>
    <p align="left">For backwards we only support 'backwards 2', 'forwards 2'</li>
  <li>
    <p align="left">For backwards compability, a &quot;@&quot; is interpreted as &quot;[backwards 2]&quot;.</li>
  <li>
    <p align="left">You can have [variable top] in place of a letter, e.g. '9' &lt; [variable top]. This causes all non-zero primary weights at or below that 
    value to be variable.</li>
  <li>
    <p align="left">You can have [top] in a reset, e.g. &amp; [top] &lt; 'a'. [top] represents a value above all others in the UCA, but below all implicit 
    weights, for now and into the future. We reserve sufficient room between top and the lowest implicit such that most tailorings can occupy only 2 byte 
    primaries. This allows CJK reorderings to be relatively compact. The location of [top] is A0.</li>
</ul>
<blockquote>
  <p align="left"><b>Note: </b>The following syntax will be added in the future to allow tailoring of rearrangement. For now, it is hard-coded.<br>
  [rearrange on: 0E40,0E41,0E42,0E43,0E44,0EC0,0EC1,0EC2,0EC3,0EC4]<br>
  [rearrange off: 0E40...]<br>
  </p>
</blockquote>
<h3 align="left">Extensions</h3>
<h4 align="left">Normalization</h4>
<p align="left">Since normalization can slow down processing, we provide a rule that lets you turn it on or off by default in the tailoring. This should be used 
with caution.</p>
<pre>[normalization off]</pre>
<h4 align="left">Case</h4>
<p align="left">We add some syntax for controlling case behavior: setting the level on or off; and determining whether the case ordering is &quot;upper&quot; 
first, &quot;lower&quot; first, or &quot;default&quot;. If 'default', then the tertiary mask is 0x7F, otherwise it is 0xFF. If upper, then the case bit is 
inverted. If lower, then the case bit is left alone.</p>
<div align="left">
  <pre>[caseLevel on]</pre>
</div>
<div align="left">
  <pre>[caseFirst lower]</pre>
</div>
<p align="left">The Japanese tailoring, for example, would set caseLevel ON.</p>
<h4 align="left">Before</h4>
<p align="left">There are occasionally situations where you need to tailor to before a given character X. While in theory this just means looking in the UCA for 
the character before X, that is not robust: if a later version of UCA inserts an extra character, the old rule would be broken. We allow this by supplying extra 
syntax.</p>
<div align="left">
  <pre>[before <i>n</i>] x</pre>
</div>
<p align="left">The <i>n</i> is a weight level: 1 for primary, 2 for secondary, 3 for primary. For example, &quot;[before 2] x&quot; refers to the character 
highest character that is secondary-less than x. This construct can only be used immediately after a reset, such as in:</p>
<div align="left">
  <pre align="left">&amp; [before 1] d &lt; ch</pre>
</div>
<p align="left">This will put &quot;ch&quot; immediately before &quot;d&quot; in weight.</p>
<h4 align="left">Script Order (post 1.8)</h4>
<p align="left">You can create a ScriptOrder array based on the script of letter1, then script of letter 2, etc. This <a href="#Overriding script orders">overrides</a> 
the UCA order. E.g.</p>
<div align="left">
  <pre>[scriptOrder ฮฑ, ั, f]</pre>
</div>
<p align="left">&nbsp;In case of any conflict, the later ones are ignored. E.g. in the following, the &quot;ฮฒ&quot; is ignored:</p>
<div align="left">
  <pre>[scriptOrder ฮฑ, ั, f, ฮฒ]</pre>
</div>
<p align="left">The special symbol &quot;ยค&quot; stands for all non-variable CEs that are below &quot;a&quot; in the UCA.</p>
<h4 align="left">Charset (post 1.8)</h4>
<p align="left">Two pieces of syntax must be added. Charset is only valid if there is a preceding charsetname.</p>
<pre>[charsetname SJIS]

[charset 3400-9FAF]</pre>
<h4><a name="Undefined_Positioning">Undefined Positioning</a> (Post v1.8)</h4>
<pre>[undefined]</pre>
<p>This is a syntax element that puts all undefined code points at that location. This behaves like the UNDEFINED option described in UCA, in that it puts all 
implicit CEs at that point instead of at the end. There is always a primary difference with [undefined]; that is,</p>
<p align="center">&quot;&amp; X , [undefined] , Y&quot; is treated as if it were &quot;&amp; X &lt; [undefined] &lt; Y&quot;</p>
<blockquote>
  <p><b>Note: </b>A specified position for [undefined] will generate significantly longer sort keys than if all undefined values are left at the end. See <a
  href="#Positioning_Implicit_CEs">Positioning Implicit CEs</a>. Script Reordering can be used instead, since the sort keys are unchanged in length.</p>
</blockquote>
<h2 align="left">9 <a name="Versioning">Versioning</a></h2>
<p align="left">If an index has been built with sort keys, it is vital to know when a new version would generate different sorting results, or when sort keys 
are not binary-identical. There are several important versions.</p>
<ul>
  <li>
    <p align="left">the runtime code (determines the structure of the sort key),</li>
  <li>
    <p align="left">the CE builder code (determines the CE contents)</li>
  <li>
    <p align="left">the UCA table/Unicode version (which will change over time, as characters are added), and</li>
  <li>
    <p align="left">the Tailoring table (which may change for a particular language, e.g. as more becomes known about the language or as if the laws in the 
    country change).</li>
  <li>
    <p align="left">the charset version (only applicable if the tailoring includes a charset parameter).</li>
</ul>
<p align="left">The code and/or UCA/Unicode values are bumped with any version of ICU that changes them in a way <i>that is incompatible with the past usage for 
assigned characters</i>. That is, if a new version of ICU merely adds newly assigned characters at the very end (below [top]), or in a way that would not affect 
tailoring, this field will <i>not</i> be changed. If a new version changes mappings, or interleaves new characters in a way that would affect tailorings, we 
will bump this version.</p>
<p align="left">The tailoring version comes from the resource. The Charset version is zero if no charset is used, otherwise it is a charset version. We will try 
to keep these values as stable as possible, but they may change in the future. In particular, as new characters are assigned, UCA will change.</p>
<blockquote>
  <p align="left"><b>Note: </b>we may in the future offer an API that detects, for a given repertoire of characters, whether sort keys change between versions. 
  This could be used to minimize sort index rebuilds.</p>
</blockquote>
<div align="center">
  <table border="1" cellspacing="1">
    <tr>
      <td width="20%" bgcolor="#00FF00" align="center">
        <p align="left"><font size="2">Runtime code</font></p>
      </td>
      <td width="20%" bgcolor="#00FF00" align="center">
        <p align="left"><font size="2">CE builder code</font></td>
      <td width="20%" bgcolor="#00FF00" align="center">
        <p align="left"><font size="2">Charset</font></p>
      </td>
      <td width="20%" bgcolor="#00FF00" align="center">
        <p align="left"><font size="2">UCA/Unicode</font></p>
      </td>
      <td width="20%" bgcolor="#00FF00" align="center">
        <p align="left"><font size="2">Tailoring</font></p>
      </td>
    </tr>
  </table>
</div>
<p align="left">We will return this as a single 32-bit int. The exact distribution of bits is private: the important feature is that if two versions are 
different, then sort keys may be different. In future versions of ICU, if you ask for a collator with this version (and the same locale and sorting parameters), 
you will get the same binary sort key. <i>However, it is your own responsibility to save any parameter settings that could change the binary sort key 
(normalization, strength, etc)! If you use customized rules, management is also left up to you.</i></p>
<blockquote>
  <p align="left"><b>Note: </b>This depends on the version of ICU being unmodified. If you delete the old data tables, e.g. to save space in a given 
  environment, then you will not be able to get the identical sort. In that case, at least the change in version tells you that you need to rebuild your sort 
  index.</p>
</blockquote>
<p align="left">In addition, a hash of the Tailoring table is available for security checks.</p>
<h3 align="left">9.1 <a name="Registration">Registration</a> (post 1.8)</h3>
<p align="left">Registration lets you register a collator, whether from the system or a custom-built one from rules, for a Locale. If any function in that 
address space then creates a collator afterwards using that locale, they get a copy of the registered collator. This is not persistent over reboots. See the ICU 
User Guide for more information.</p>
<h2 align="left">10 <a name="API">API</a></h2>
<p>Readers should be familiar with the current API (also used in Java) before proceeding.</p>
<ul>
  <li><a href="http://oss.software.ibm.com/icu/apiref/ucol_h.html#_details">Current ICU Collation API</a></li>
  <li><a href="http://java.sun.com/j2se/1.3/docs/api/java/text/Collator.html">http://java.sun.com/j2se/1.3/docs/api/java/text/Collator.html</a></li>
  <li><a href="http://java.sun.com/j2se/1.3/docs/api/java/text/RuleBasedCollator.html">http://java.sun.com/j2se/1.3/docs/api/java/text/RuleBasedCollator.html</a></li>
  <li><a href="http://java.sun.com/j2se/1.3/docs/api/java/text/CollationElementIterator.html">http://java.sun.com/j2se/1.3/docs/api/java/text/CollationElementIterator.html</a></li>
  <li><a href="http://java.sun.com/j2se/1.3/docs/api/java/text/CollationKey.html">http://java.sun.com/j2se/1.3/docs/api/java/text/CollationKey.html</a></li>
</ul>
<p>We add some API to C and C++ to allow control over additional features, unify feature control system, manage memory more efficiently and improve performance 
in some special cases. None of these are breaking changes, although we do have two semantic changes.</p>
<ol>
  <li>
    <p align="left">The RuleBasedCollator class constructor and corresponding C ucol_open take only the tailoring rules as input, not the whole set.</li>
  <li>
    <p align="left">The default decomposition mode is NFD for compatibility with UCA, instead of NFKD. However, we offer more options: the decomposition can be 
    set on or off in the tailoring.</li>
</ol>
<h3>10.1 <a name="General_Attribute_API">General Attribute API</a></h3>
<h4>C API</h4>
<pre>void ucol_setAttribute(
  UCollator *coll,
  UColAttribute attr,
  UColAttributeValue value,
  UErrorCode *status);

UColAttributeValue ucol_getAttribute(
  UCollator *coll,
  UColAttribute attr,
  UErrorCode *status);</pre>
<h4>C++ API</h4>
<pre>void setAttribute(
  UColAttribute attr,
  UColAttributeValue value,
  UErrorCode &amp;status);

UColAttributeValue getAttribute(
  UColAttribute attr,
  UErrorCode &amp;status);</pre>
<p>These API are used for setting and getting certain attributes of the collation framework. Current attribute types are:</p>
<pre>UCOL_FRENCH_COLLATION,   /* attribute for direction of secondary weights*/
UCOL_ALTERNATE_HANDLING, /* attribute for handling variable elements*/
UCOL_CASE_FIRST,         /* which goes first, lower case or uppercase */
UCOL_CASE_LEVEL,         /* do we have an extra case level */
UCOL_DECOMPOSITION_MODE, /* attribute for normalization */
UCOL_STRENGTH            /* attribute for strength */</pre>
<p>Allowable values for the attributes vary from the attribute to attribute. They are summarized in the following list:</p>
<pre>/* accepted by most attributes */
 UCOL_DEFAULT,

/* for UCOL_FRENCH_COLLATION &amp; UCOL_CASE_LEVEL &amp; UCOL_DECOMPOSITION_MODE */
 UCOL_ON,
 UCOL_OFF,

/* for UCOL_ALTERNATE_HANDLING */
 UCOL_SHIFTED,
 UCOL_NON_IGNORABLE,

/* for UCOL_CASE_FIRST */
 UCOL_LOWER_FIRST,
 UCOL_UPPER_FIRST,

/* for UCOL_STRENGTH */
 UCOL_PRIMARY,
 UCOL_SECONDARY,
 UCOL_TERTIARY,
 UCOL_DEFAULT_STRENGTH = UCOL_TERTIARY,
 UCOL_QUATERNARY,
 UCOL_MAXIMUM_STRENGTH</pre>
<p>The &quot;Universal&quot; attribute value is UCOL_DEFAULT, which sets the value of the attribute to the default set by the tailoring rules. Attribute values 
that are inappropriate for the particular attribute types result in U_ILLEGAL_ARGUMENT_ERROR.</p>
<h3>10.2 <a name="Memory_API">Memory API</a></h3>
<p>We add a safeClone, so that people can more easily manage collators among threads. We will allow stack allocation. If created on the stack, the close 
function does not free the main storage (but may free internal storage). We can consider making the close operation a macro, so that there is zero overhead if 
nothing needs doing.</p>
<h4>C API</h4>
<pre><font face="Courier New" color="#000000" size="2">UCollator *ucol_safeClone(const UCollator *coll,
  void *stackBuffer,
  uint32_t bufferSize,
  UErrorCode *status);</font></pre>
<h4>C++ API</h4>
<pre><font face="Courier New" color="#000000" size="2">Collator* safeClone(void);</font></pre>
<p align="left">In the future, we could add an open function that allows stack allocation.</p>
<h3>10.3 <a name="Rule_Retrieval_API">Rule Retrieval API</a></h3>
<p>The new API can return either the full UCA rule set plus the tailoring (the getRules API will just return the tailoring).</p>
<h4>C API</h4>
<pre>int32_t ucol_getRulesEx(const UCollator *coll,
  UColRuleOption delta,
  UChar *buffer,
  int32_t bufferLen);</pre>
<h4>C++ API</h4>
<pre>UnicodeString getRules(UColRuleOption delta);</pre>
<p>The delta parameter is from the following range:</p>
<pre>UCOL_TAILORING_ONLY,
UCOL_FULL_RULES</pre>
<h3>10.4 <a name="Custom_Data_API">Custom Data API</a></h3>
<p>We allow user to supply their own function for fetching characters.
<h4>C API</h4>
<pre>U_CAPI UCollationResult ucol_strcollinc(const UCollator *coll, 
  UCharForwardIterator *source,
  void *sourceContext,
  UCharForwardIterator *target,
  void *targetContext);</pre>
<p>Where the iterating function returns either a regular UChar value, or FFFF if there are no more characters to be processed. It is defined as:</p>
<pre>typedef UChar UCharForwardIterator(void *context);</pre>
<h4>C++ API</h4>
<p>The C++ equivalent relies on the implementation of the abstract ForwardCharacterIterator class:</p>
<pre>virtual EComparisonResult compare(
  ForwardCharacterIterator &amp;source,
  ForwardCharacterIterator &amp;target);</pre>
<h3>10.5 <a name="Sort_Key_API">Sort Key API </a>(C++ only)</h3>
<p>In order to have the same functionality as in C, the C++ API gets the following functions:
<pre>virtual int32_t getSortKey(
  const UnicodeString&amp; source,
  uint8_t *result,
  int32_t resultLength) const;

virtual int32_t getSortKey(
  const UChar *source,
  int32_t sourceLength,
  uint8_t *result,
  int32_t resultLength) const;</pre>
<p>These API store the sort key in an uint8_t (e.g. byte) array. The functions do the standard preflighting.</p>
<h3 align="left">10.6 <a name="Script_Order_API">Script Order API</a> (post 1.8)</h3>
<div align="left">
  <pre>char* temp = &quot;\u03B1, \u044F, f&quot;;
// use unescape to put into uchar* tempu;
ucol_setScriptOrder(aCollator, tempu);</pre>
</div>
<p align="left">Puts the characters in temp into a scriptOrder array. Whitespace and commas are ignored. This <a href="#Overriding script orders">overrides</a> 
the tailored order, which in turn overrides the UCA order.</p>
<h4 align="left"><a name="Overriding script orders">Overriding script orders</a></h4>
<p align="left">When a script order overrides another you merge them together in the following way, with the overriding script order as the master, and the 
overridden one as slave:</p>
<blockquote>
  <p align="left">Start with the master. Find the first script in the slave that is also in the master. If there is none, add all slave values at end of master, 
  and terminate. If there is one, insert all preceding slave values before the matching value in the master. Set the current_position to be <i>after</i> the 
  matching value in the master. Successively add the remaining elements from the slave, as follows:</p>
  <ul>
    <li>
      <p align="left">If the slave value is in the master, set the current_position to <i>after</i> that master value</li>
    <li>
      <p align="left">If the slave value is not in the master, insert <i>before</i> the current_position and increment current_position.</li>
  </ul>
</blockquote>
<p align="left"><i>Example (using characters to stand for scripts):</i></p>
<blockquote>
  <p align="left">Master: ฮฑ, ั, f</p>
  <p align="left">Slave:ไบฐ, f, ยค, ฮฑ</p>
  <p align="left">Results: ฮฑ, ั, ไบฐ, f, ยค</p>
</blockquote>
<p align="left">Before execution, these characters are used to form a permuting scriptOrder array, as described in the implementation section.</p>
<h3 align="left">10.7 <a name="Charset_Ordering_API">Charset Ordering API</a> (post 1.8)</h3>
<p align="left">The following methods need to be added to charset converters, before we can support the charset feature.</p>
<div align="left">
  <pre>/** Returns CE values for given character. The first is the return, the rest
 *  are filled in.
 *  Resets ceBufferEnd to indicate length in queue. Can never return more than CEBUFFER_MAX.
 *  Must be well-formed CEs!!
 *  the data represents the primary weight bytes to append to the first CE.
 */

ce = cvt_getOrdering(Converter cvt, int data, uchar32 ch, int[] ceBuffer, int* ceBufferEnd);</pre>
</div>
<p align="left">The top 8 bits of the data is used as the first primary weight: the others are extensions.</p>
<div align="left">
  <pre>/** Returns a version ID. This is a byte, which we bump in ICU 
  * whenever the collation result in getOrdering would differ because of data changes.
 */

uint8_t  cvt_getColVersion(Converter cvt);</pre>
</div>
<h3 align="left">10.8 <a name="Loose_Match_Utility">Loose Match API</a> (post 1.8)</h3>
<p align="left">This is a useful utility function for searching within a sorted list of sort keys. It takes a sort key and a level (greater than 1), and 
produces upper- or lower-bound sort keys respectively. That is, it can be used to select values such that lowerBound &lt;= sortKey &lt; upperbound, <i>at the 
requested level</i>. For example, take a sort key for &quot;Smith&quot;. The generated lowerbound and upperbound sort keys for level 3 would match everything 
from &quot;smith&quot; to &quot;SMITH&quot;, with any ignorable characters. If the level were 2, then it would match any of those, plus any combination with 
accents. By using bounds from different keys, larger ranges can be selected.</p>
<ul>
  <li>
    <p align="left">The <span style="font-variant: small-caps">inclusive</span> lower bound is easy. Copy the input key up to the 01 terminating the requested 
    level. Append a 00 and stop.</li>
  <li>
    <p align="left">The <span style="font-variant: small-caps">exclusive </span>upper bound is only slightly harder. Do the same as the lower bound, but then 
    start backing up through the bytes. If a byte is neither FF nor 01, add one and stop. Otherwise, set it to 00 and continue to the previous byte.</li>
</ul>
<p align="left">Doing <span style="font-variant: small-caps">exclusive </span>lower bound or <span style="font-variant: small-caps">inclusive</span> upper bound 
would take a bit more thought.</p>
<h3 align="left">10.9 <a name="Merge_Comparison_API">Merge Comparison API</a> (post 1.8)</h3>
<p align="left">This is a useful utility function for combining fields in a database. When sorting multiple fields, such as lastName and firstName, there are 
two alternatives. The first is to sort simply by lastName, then sort within lastNames by first name. That, however, leads to normally undesired results. For 
example, consider the following (where alternates are SHIFTED).</p>
<blockquote>
  <p align="left">diSilva, John<br>
  diSilva, Fred<br>
  di Silva, John<br>
  di Silva, Fred<br>
  dรญsilva, John<br>
  dรญsilva, Fred</p>
</blockquote>
<p align="left">The problem is that substantially primary-different first names should swamp tertiary-different (or secondary-different) last names. One course 
of action is to sort the first fields only by primary difference. However, this will result in non-primary differences in the last name being ignored when they 
shouldn't be:</p>
<blockquote>
  <p align="left">diSilva, John<br>
  dรญsilva, John<br>
  di Silva, John<br>
  di Silva, Fred<br>
  diSilva, Fred<br>
  dรญsilva, Fred</p>
</blockquote>
<p align="left">Notice in the second example that the first names are now correctly ordered, but ignoring differences in accent, case or spacing in the first 
names causes them to come out in essentially random order. There are two solutions to this. First is to sort a calculated field, which is lastName + separator + 
firstName, where the separator is chosen to be a character that has a non-ignorable primary weight, and sorts lower than anything that could be in lastName. For 
example, the following have the lowest UCA non-zero, non-primary weights (depending on the alternate weight setting):</p>
<ul>
  <li>
    <p align="left">U+02D0 MODIFIER LETTER TRIANGULAR COLON (if SHIFTED)</li>
  <li>
    <p align="left">U+0009 HORIZONTAL TABULATION (if not SHIFTED)</li>
</ul>
<p align="left">However, that is not the most satisfactory result, since (a) you may have the sort keys for lastName and firstName already and don't want to 
waste time recomputing them, and (b) you have to make sure that lastName cannot not contain the separator character.</p>
<p align="left">An alternative is to have a mergeSortKeys function. This takes a list of sort keys, and concatenates them together <i>level-by-level</i>. For 
example, given:</p>
<ul>
  <li>
    <p align="left"><b>aa bb cc <font color="#FF0000">01</font> dd ee ff gg <font color="#FF0000">01</font> hh ii <font color="#FF0000">00</font></b></li>
  <li>
    <p align="left"><font color="#0000FF"><b>jj kk </b></font><b><font color="#FF0000">01</font></b><font color="#0000FF"><b> mm nn oo </b></font><b><font
    color="#FF0000">01</font></b><font color="#0000FF"><b> pp qq rr </b></font><b><font color="#FF0000">00</font></b></li>
  <li>
    <p align="left"><font color="#003300"><b>ss tt uu vv </b></font><b><font color="#FF0000">01</font></b><font color="#003300"><b> ww xx </b></font><b><font
    color="#FF0000">01</font></b><font color="#003300"><b> yy zz </b></font><b><font color="#FF0000">00</font></b></li>
</ul>
<p align="left">The result is one sort key that has each of the primary levels, then each of the secondary levels, and so on. Each list of weights at each level 
is separated with a 02, which we reserve for this purpose</p>
<ul>
  <li>
    <p align="left"><b>aa bb cc <font color="#FF0000">02</font> </b><font color="#0000FF"><b>jj kk </b></font><b><font color="#FF0000">02</font></b><font
    color="#0000FF"><b> </b></font><b><font color="#003300">ss tt uu vv </font><font color="#FF0000">01</font><font color="#003300"> </font></b><b>dd ee ff gg <font
    color="#FF0000">02</font> </b><font color="#0000FF"><b>mm nn oo </b></font><b><font color="#FF0000">02</font></b><font color="#0000FF"><b> </b></font><font
    color="#003300"><b>ww xx </b></font><b><font color="#FF0000">01</font></b><font color="#003300"><b> </b></font><b><font color="#003300">h</font>h ii <font
    color="#FF0000">02</font></b> <font color="#0000FF"><b>pp qq rr </b></font><b><font color="#FF0000">02</font></b><font color="#0000FF"><b> </b></font><b><font
    color="#003300">yy zz </font><font color="#FF0000">00</font></b></li>
</ul>
<p align="left">If this function is used, then the correct sorting can be produced for multiple fields. All the level information is taken into account:</p>
<blockquote>
  <p align="left">diSilva, John<br>
  di Silva, John<br>
  dรญsilva, John<br>
  diSilva, Fred<br>
  di Silva, Fred<br>
  dรญsilva, Fred</p>
</blockquote>
<p align="left">A similar function is available for string comparison, that compares one list of strings against another. For both sort keys and string 
comparison, the client must ensure that the same number of strings are being compared on either side.</p>
<h1>11 <a name="Issues">Issues</a></h1>
<p>The following section lists issues and possible future additions.</p>
<h3>11.1 <a name="Parameterized_SHIFTED">Parameterized SHIFTED</a> (post 1.8 possibility)</h3>
<p>We could offer a further variation on Variable. Instead of having SHIFTED always shift the primary down to the 4th level, we could allow it to shift to the 
3rd level or second level. (Note: ICU 1.6 used 3rd level), before all other elements at that level. Here is an example of the difference it would make.</p>
<table border="1">
  <tr>
    <th width="33%">Not Ignored</th>
    <th width="33%">Shifted to 2rd</th>
    <th width="33%">Shifted to 3rd</th>
    <th width="34%">Shifted to 4th</th>
  </tr>
  <tr>
    <td align="center">di silva<br>
      di Silva<br>
      Di silva<br>
      Di Silva<br>
      <font color="#FF0000"><b>Dickens</b></font><br>
      disilva<br>
      diSilva<br>
      Disilva<br>
      DiSilva</td>
    <td align="center"><font color="#FF0000"><b>Dickens</b></font><span style="background-color: #FF0000"><br>
      </span>di silva<br>
      di Silva<br>
      Di silva<br>
      Di Silva<br>
      disilva<br>
      diSilva<br>
      Disilva<br>
      DiSilva</td>
    <td align="center"><font color="#FF0000"><b>Dickens</b></font><span style="background-color: #FF0000"><br>
      </span>di silva<br>
      di Silva<br>
      disilva<br>
      diSilva<br>
      Di silva<br>
      Di Silva<br>
      Disilva<br>
      DiSilva</td>
    <td align="center"><font color="#FF0000"><b>Dickens</b></font><span style="background-color: #FF0000"><br>
      </span>di silva<br>
      disilva<br>
      di Silva<br>
      diSilva<br>
      Di silva<br>
      Disilva<br>
      Di Silva<br>
      DiSilva</td>
  </tr>
</table>
<p align="left">Although this is an algorithmic change, to allow for the possibility of adding this in the future we reserve one additional value in the 
Fractional UCA table on the 2nd and 3rd levels, a value that is before UNMARKED. This means that UNMARKED goes to 04. Any variable primary that is shifted down 
will be appended to that value.</p>
<p align="left"><i>Example:</i></p>
<table border="1" cellpadding="4">
  <tr>
    <th align="right">&nbsp;</th>
    <td width="36">P</td>
    <td width="36">S</td>
    <td width="36">T</td>
    <td width="36">Q</td>
  </tr>
  <tr>
    <th align="right">Original CE</th>
    <td>05</td>
    <td>92</td>
    <td>31</td>
    <td>N/A*</td>
  </tr>
  <tr>
    <th align="right">Shifted to level 2</th>
    <td>00</td>
    <td>02 05</td>
    <td>02 92</td>
    <td>N/A*</td>
  </tr>
  <tr>
    <th align="right">Shifted to level 3</th>
    <td>00</td>
    <td>00</td>
    <td>00</td>
    <td>N/A*</td>
  </tr>
  <tr>
    <th align="right">Shifted to level 4</th>
    <td>00</td>
    <td>00</td>
    <td>00</td>
    <td>05</td>
  </tr>
</table>
<p align="left"><font size="-1">* Note that unless variable handling is on, there is no 4th level generated. This is separate from whether there is an IDENTICAL 
level added, which is always simply (normalized) code points.</font></p>
<h3 align="left">11.2 <a name="Indirect Positioning">Indirect Positioning</a> (post 1.8 possibility)</h3>
<p align="left">The following are special items that can be used as reset values, so that Tailoring tables do not have to change when UCA adds more characters. 
For example, in tailoring all of CJK one can start with &amp; [last] &lt; .... to have all CJK at the end. If we had &amp;{yi syllable xxx} &lt; ..., then their 
position changes once characters are added after Yi. Here is the list of possibilities.</p>
<ul>
  <li>
    <p align="left">[last variable] last variable value</li>
  <li>
    <p align="left">[last primary ignorable] largest CE for primary ignorable</li>
  <li>
    <p align="left">[last secondary ignorable] largest CE for secondary ignorable</li>
  <li>
    <p align="left">[last tertiary ignorable] largest CE for tertiary ignorable</li>
  <li>
    <p align="left">[top] guaranteed to be above all implicit CEs, for now and in the future (in 1.8)</li>
</ul>
<blockquote>
  <p align="left"><b>Issue: </b>if we leave more of a gap after each of the above (and between scripts), and we disallow tailoring of items in say half of that 
  gap, then we are more robust regarding changes in the UCA.
</blockquote>
<hr>
<h2 align="left"><a name="Appendix_1">Appendix 1</a>: Japanese Sort Order</h2>
<p align="left">The following is the result of a test of sorting in Microsoft Office, for comparison.</p>
<p align="left">1:LEVEL base chars, length<br>
1:ใซ<br>
1:ใซใญ<br>
1:ใญ<br>
1:ใญใญ<br>
<br>
2:LEVEL plain, daku-ten, (handaku-ten)<br>
2:ใใซ<br>
2:ใใซ<br>
2:ใใญ<br>
2:ใใญ<br>
* This is a different level. Notice that the difference between ใ and ใ is ignored if there is a level 1 difference.<br>
<br>
3:LEVEL small before large<br>
3:ใใ<br>
3:ใใ<br>
3:ใใ<br>
3:ใใ<br>
* This is a different level. Notice that the difference between ใ and ใ is ignored if there is a level 2 difference<br>
<br>
4:LEVEL katakana before hiragana<br>
4:ใขใ<br>
4:ใใ<br>
4:ใขใ<br>
4:ใใ<br>
* This is a different level. Notice that the difference between ใข and ใ is ignored if there is a level 3 difference.<br>
<br>
5:LEVEL choo-on kigoo as vowel<br>
5:ใซใผใข<br>
5:ใซใผใ<br>
5:ใซใคใข<br>
5:ใซใคใ<br>
5:ใญใคใข<br>
5:ใญใคใ<br>
5:ใญใผใข<br>
5:ใญใผใ<br>
* Office handles the expansion of ใผ into different characters depending on the previous letter, so it sorts before ใค when following a ใซ, but after when 
following a ใญ. However, it is not a different level from #4, since the order does not reverse with a suffix.<br>
<br>
Thus Office has 4 levels:<br>
Level 1 = base letters<br>
Level 2 = plain, daku-ten, handaku-ten<br>
Level 3 = small, large<br>
Level 4 = katakana, hiragana, choo-on kigoo</p>
<h2 align="left"><a name="Appendix_2">Appendix 2</a>: Compressing Primary Weights</h2>
<p>The following describes a possible mechanism for compressing primary weights in sort keys. We will investigate the performance/storage tradeoff before using. 
For compression of non-secondary weights, see <a href="#Compression">Compression</a>.</p>
<h4>Mechanism</h4>
<p>Generally we will have longish sequences of letters from the same script. They will usually share the same first few bytes of primary, and differ in the last 
byte. Let's suppose that we reserve the 02 and FF bytes in final positions in primary weights. Then take the longest sequence of two-byte primary weights with 
the same initial weight XX:</p>
<pre>...XX YY XX ZZ XX WW XX MM AA....</pre>
<p>where AA is the first byte of the primary weight that does not start with XX. This is transformed into the following, where ** is FF if AA &gt; XX, and 02 if 
AA &lt; XX (or there is no AA).</p>
<pre>...XX YY ZZ WW MM ** AA...</pre>
<p>That is, we delete all XX's but the first one, then add ** at the end.</p>
<h4>But does it preserve ordering?</h4>
<p>We are guaranteed that this transformation, if performed uniformly, will sort with the same order. Look at the following example, where (a) and (b) are the 
originals, and (c) and (d) are the compressed versions:</p>
<pre>a) ...XX YY XX ZZ XX WW XX MM, AA....</pre>
<pre>b) ...XX QQ XX RR XX SS BB....</pre>
<pre>c) ...XX YY ZZ WW MM ** AA...</pre>
<pre>d) ...XX QQ RR SS ** BB...</pre>
<p>If the first difference in either case is at, say, ZZ and RR, then the orderings will be the same, since the XX's would be the same in either case, and that 
is the only difference.</p>
<p>If the sequences were the same length and identical, the compressions will be as well.</p>
<p>If the sequences are different length, but identical up through the shorter one, then we would be comparing, say, ** in (d) to MM in (c). The corresponding 
comparison in the originals will be BB in (b) to XX in (a). If BB &lt; XX, then ** is 02, which is guaranteed to be less than MM. If BB &gt; XX, then ** is FF, 
which is guaranteed to be greater. BB will never be the same as XX, since then we would have included it in the compression (since the compression takes the 
longest sequence of XX's).</p>
<h4>Implementation</h4>
<p>The implemenation is reasonably simple. We don't have to backtrack or count since we break even with compression of a sequence of two, e.g.</p>
<pre>... XX YY XX ZZ AA...</pre>
<pre>... XX YY ZZ FF AA</pre>
<p>Every time we add a primary weight, check the last first byte. If we ever get a primary key that starts with the same byte, we don't add that byte: we set a 
flag. The code would look something like:</p>
<pre>if (lastFirstByte != currentFirstByte) {
  if (compressionCount &gt; 1) {
    *p++ = (currentFirstByte &gt; lastFirstByte) ? 0xFF : 0x02;
    compressionCount = 0;
  }
  *p++ = lastFirstByte = currentFirstByte;
} else {
  ++compressionCount;
}
// add other primary weight bytes to *p, if there are any</pre>
<p>This will actually work even if the primary weights have more or fewer bytes, although sequences of identical single-byte primaries will probably be rare, 
and the compression is not especially good for triple-bytes.</p>
<p><i>Examples:</i></p>
<h5>Single-byte primaries</h5>
<pre>... XX XX XX AA ...</pre>
<pre>... XX ** AA ...</pre>
<h5>Triple-byte primaries</h5>
<pre>... XX QQ RR XX QQ PP XX SS TT AA ...</pre>
<pre>... XX QQ RR QQ PP SS TT ** AA ...</pre>
<p>We could get better compression for the triple-byte case if we compared more than just the first byte. However, this makes the bookkeeping more significant. 
Not sure if it is worth it.</p>
<h4>Data Impact</h4>
<p>For first bytes, we already exclude 00, 01, Dx, Ex, Fx, leaving 206 values. For second bytes, we would need to disallow 02 and FF (and we already remove 00 
and 01). That would give us 252 values. For tailoring, we have to leave a gap of 1, leaving 126 values. That gives us 25,956 possible two-byte primaries instead 
of 26,162 possible two-byte primaries, which is not a huge reduction.</p>
<h4>Performance</h4>
<p>If the above code is about right, then in the worst case (no common first bytes of primaries), we would have an extra byte comparison,&nbsp; boolean test, 
and byte set per character. On the other hand, the memory requirements for sort keys would probably be reduced sufficiently that it would be an overall win. 
(This would be especially true for disk-based sort indexes!)</p>
<h2><a name="Appendix_3">Appendix 3: Data Files</a></h2>
<p>The following data files are included for reference:</p>
<p><a href="FractionalUCA.zip">FractionalUCA.txt<br>
</a><a href="log-FractionalUCA.txt">log-FractionalUCA.txt</a></p>
<blockquote>
  <p>Table of Fractional CEs generated from UCA. The format is described in the header:</p>
  <div align="left">
    <blockquote>
      <pre align="left">code; fractional_ce  # uca_ce # name</pre>
    </blockquote>
  </div>
  <p align="left">There are extra tabs between the levels, just to make it easier to see transitions in weight length. The second file contains a summary of the 
  assignments made in generating the Fractional UCA file.</p>
</blockquote>
<p><a href="CollationTest_NON_IGNORABLE.zip">CollationTest_NON_IGNORABLE.txt<br>
</a><a href="CollationTest_SHIFTED.zip">CollationTest_SHIFTED.txt</a></p>
<blockquote>
  <p>Contains list of lines in UCA sorted order, for testing UCA conformance. There are two versions, depending on the alternate setting.</p>
</blockquote>
<p><a href="UCA_Rules.zip">UCA_Rules.txt<br>
UCA_Rules_With_Names.txt</a></p>
<blockquote>
  <p>UCA table re-expressed as Java/ICU syntax rules. UTF-8 format, with BOM. Second version adds character names in comments.</p>
</blockquote>
<h2>Appendix 4: <a name="Requirements">Requirements</a></h2>
<p>This document reads as if all the following requirements and options are being done, so that the architecture is complete for the future. However, options 
will only be considered in the 1.7/1.8 timeframe if implementation falls out of the rearchitecture work.&nbsp; (Some 1.8 functionality may be in 1.7, if it is 
easier to integrate then.)</p>
<h3>ICU4c 1.7 Requirements <font size="3">โ</font> Not in priority order</h3>
<ol>
  <li>All of the current features will be maintained (with one semantic change โ see API).</li>
  <li>Improve performance to the requisite level. First priority is string compare, next is sortkey. (perf)</li>
  <li>Fix Japanese tailoring data to be more compatible [but see 1.8 for complete story] (data)
    <ul>
      <li>Level 1 = base letters,</li>
      <li>Level 2 = plain, daku-ten, handaku-ten</li>
      <li>Level 3 = small (katakana, hiragana, choo-on kigoo), large (katakana, hiragana, choo-on kigoo)</li>
    </ul>
  </li>
  <li>Add SafeClone API (multi-thread)</li>
  <li>Allow sort-keys to be valid C-Strings: e.g. avoid null bytes, add null-byte terminator.
    <ul>
      <li>This makes our sort keys comparable with strcmp() in addition to memcmp(). It is like ANSI C strxfrm() and Win32 LCMapString().</li>
    </ul>
  </li>
  <li>Add all API and rule syntax, even if it is not functional in this release</li>
  <li><b>Binary Compatibility of Sort Keys</b>
    <ol>
      <li><b>1.7 is an enhancement release, not a reference release.</b></li>
      <li><b>1.7 sort keys are only for testing, not for release products.</b></li>
      <li><b>1.7 sort keys will not be compatible with 1.6 sort keys or 1.8 sort keys.</b></li>
    </ol>
  </li>
</ol>
<h3>ICU4j 1.8 Requirements <font size="3">โ</font> Not in priority order</h3>
<ol>
  <li>Be fully conformant to the UCA (function)</li>
  <li>Allow the main UCA table to be flat: static, read-only, and shared among languages. (footprint, perf)</li>
  <li>Other performance improvements as described in this document. (perf)</li>
  <li>Reduce A-Z primaries to single byte weight (perf, footprint)</li>
  <li>Add complete versioning (function)</li>
  <li>Support additional Japanese case level.
    <ul>
      <li>Level 1 = base letters,</li>
      <li>Level 2 = plain, daku-ten, handaku-ten</li>
      <li>Level 3 = small, large</li>
      <li>Level 4 = hiragana, katakana, choo-on kigoo
        <ul>
          <li>A variant could actually support 5-level Japanese sorting, by making the choo-on kigoo be equal at the 4th level, and choosing IDENTICAL strength. 
            Because of the code point order, this would have the effect of providing the right ordering. However, it would make the sort keys much larger.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Provide parametric case reversal, e.g. upper before lower or lower before upper (function: for Danish std)</li>
  <li>Ignore accents (actually ignore all levels <i><b>except</b></i> Primary and Case Level) (function)</li>
  <li>Provide better surrogate support (req. for GB 18030 and Unicode 3.1)</li>
  <li>Use compression techniques for shorter sort-keys, reducing memory and database footprint (perf, footprint)</li>
  <li>Binary Compatibility of Sort Keys</li>
  <ol>
    <li>1.8 sort keys will not be compatible with 1.6 sort keys or 1.7 sort keys.</li>
    <li>However, all future versions will provide a mechanism for generating 1.8-binary-compatible sort keys. See <a href="#Versioning">Versioning</a></li>
  </ol>
</ol>
<h3>Post 1.8 Requirements</h3>
<ol>
  <li>Charset Sorting (special value in rules indicates codes are sorted by charset values): (footprint, maintenance)</li>
  <li>Script Order (allow parametric rearrangement of scripts, e.g. Japanese &lt; Latin &lt; Greek vs. Latin &lt; Greek &lt; Japanese) (function)</li>
  <li>Registration of Collations.</li>
  <li>Surrogate tables. Surrogates are already handled, but the special tables would reduce the footprint and memory usage substantially where large numbers of 
    supplementary characters are added.</li>
  <li>Tailoring to add characters <i>before</i> other characters.</li>
  <li>Undefined value positioning</li>
</ol>
<p>These features are not completely described here, but sufficient information should be provided so that we don't make design decisions that would make them 
harder (or impossible) to do in the future.</p>
<h3>2.1 <a name="Performance">Performance</a></h3>
Main items (not in priority order)
<ul>
  <li>Coding style
    <ul>
      <li>Rewrite core code in C. C++ API will wrap the C core code.</li>
      <li>Avoid use of objects.</li>
      <li>Avoid function calls.</li>
      <li>Fast-path Latin1.</li>
    </ul>
  </li>
  <li>Restructure tables
    <ul>
      <li>Use flat-file to speed initialization, share memory</li>
      <li>Use static Fractional UCA with separate tailoring to minimize memory usage</li>
    </ul>
  </li>
  <li>Rearchitect CE fetching, sort-key generation
    <ul>
      <li>Change to use newer fetch/sort-key generation from CEs, as described below.</li>
      <li>Use stack memory buffers for common case (with expansion if necessary).</li>
      <li>Don't use two-pass to find size first.</li>
      <li>Speed up Collation Element retrieval.</li>
    </ul>
  </li>
  <li>Speed up Normalization performance
    <ul>
      <li>Avoid normalization where possible. Use CheckFCD for this.</li>
      <li>Speed up the main normalization code.</li>
    </ul>
  </li>
  <li>For string compare, check for identical prefixes.</li>
  <li>Comparisons will be done against Win32 SDK CompareString() and LCMapString() APIs, to judge performance quality.</li>
</ul>
<h2><a name="Magic_Bytes">Appendix 5: Magic Bytes</a></h2>
<p>The following byte values in sort keys have special significance</p>
<table border="1" cellspacing="0" cellpadding="3">
  <tr>
    <th>Primary</th>
    <th>Description</th>
    <th>Sec</th>
    <th>Ter*</th>
    <th>Sec/Ter Description</th>
  </tr>
  <tr>
    <td>00</td>
    <td>Sort key terminator</td>
  </tr>
  <tr>
    <td>01</td>
    <td colspan="4">Level (Strength) separator</td>
  </tr>
  <tr>
    <td>02</td>
    <td colspan="4">Multi-field separator</td>
  </tr>
  <tr>
    <td>03</td>
    <td colspan="4">Primary Compression LOW (Sec./Ter = SHIFTED LEAD)</td>
  </tr>
  <tr>
    <td>04</td>
    <td colspan="4">Tailoring Gap</td>
  </tr>
  <tr>
    <td>05</td>
    <td colspan="4">Lowest UCA&nbsp; (Sec./Ter also = COMMON)</td>
  </tr>
  <tr>
    <td>07..78</td>
    <td>Other UCA values (Unicode 3.0)</td>
    <td colspan="2">06..85</td>
    <td>Secondary/Tertiary Compression Gap</td>
  </tr>
  <tr>
    <td>79..9F</td>
    <td>Gap for future UCA values</td>
    <td colspan="2">86</td>
    <td>Tailoring Gap</td>
  </tr>
  <tr>
    <td>A0</td>
    <td>TOP (no future UCA values will be at this or higher)</td>
    <td colspan="2">87</td>
    <td>Second Lowest UCA</td>
  </tr>
  <tr>
    <td>A0..EB</td>
    <td>Tailoring Gap</td>
    <td colspan="3">&nbsp;</td>
  </tr>
  <tr>
    <td>E8..EB</td>
    <td>CJK Ideograph Implicits</td>
    <td>EF</td>
    <td>FD</td>
    <td>Highest UCA (Unicode 3.0)</td>
  </tr>
  <tr>
    <td>EC..EF</td>
    <td>Implicits</td>
    <td>EF</td>
    <td>FD</td>
    <td>Highest UCA (Unicode 3.0)</td>
  </tr>
  <tr>
    <td>F0-FF</td>
    <td>SPECIAL</td>
    <td>F0..FE</td>
    <td>FE</td>
    <td>Gap for future UCA values</td>
  </tr>
  <tr>
    <td>FF</td>
    <td>Primary Compression HIGH</td>
    <td colspan="2">FF</td>
    <td>Tailoring Gap</td>
  </tr>
</table>
<ul>
  <li>The tertiary values are compressed in the CE to 00..3F. When the case bits are on, these can range up to 7F. In Sort Keys, these are expanded by to leave 
    a gap. If the case bits are used, the gap is 40, otherwise it is 80.</li>
  <li>All trail bytes can be 03..FF. UCA trail bytes will always be odd, so there are 126 possible values.</li>
  <li>The values above are fractional, and don't include the trailing bytes. Some important values:
    <ul>
      <li>First Possible Implicit: E8 96 5B</li>
      <li>Last Possible Implicit: EF F4 20 81</li>
      <li>Highest Actual UCA (3.0) Values
        <ul>
          <li>Primary: 78 7C for BOPOMOFO LETTER IU</li>
          <li>Secondary: E1 F1, e.g. for IDEOGRAPHIC NUMBER ZERO</li>
          <li>Tertiary: 3D, e.g. for FRACTION NUMERATOR ONE</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>TOP_FACTOR2 = 0.5, since secondaries are probably about equally distributed.</li>
  <li>TOP_FACTOR3 = 0.67, since cased letters will cause&nbsp; a weighting towards higher values.</li>
</ul>
<h2><a name="Testing">Appendix 6: Testing</a></h2>
<p>The following are some of the tests we use.</p>
<ol>
  <li>In all tests, use both sortkey comparison and strcol comparison. The results <b>must</b> be identical. Also iterate forward and backward through the 
    strings. The results must be identical.</li>
  <li>Check that all characters sort as in UCA ConformanceTest.txt</li>
  <li>Check that for all characters 0000 to 10FFFF, sortkey(x) = sortkey(NFC(x)) = sortkey(NFD(x))
    <ol>
      <li>Check that every string that is FCD equal to x has the same sort key as x, even if normalization is off.</li>
    </ol>
  </li>
  <li>Check that every tailoring character sorts correctly in the output.
    <ol>
      <li>That is, given the rule &quot;&amp;a &lt; b &lt; c &lt;&lt; d &lt; e&quot;, check that a &lt; b and b &lt; c and c &lt;&lt; d, and d &lt; e, and e 
        &lt; nextUCAAfter(a, primary)</li>
    </ol>
  </li>
  <li>On all UCA + tailored characters, check for illegal byte ranges (00..03, primary F0..FE, secondary/tertiary 06..85) UCA: (04, secondary/tertiary 86, other 
    tailoring gaps);
    <ol>
      <li>check other restrictions for collation element iterator</li>
    </ol>
  </li>
  <li>Serialize to a file sortkeys for all assigned Unicode characters in the current version of Unicode, plus any tailored char for each tailoring, plus 
    collation element iterator results for both. This is used to check binary compatibility for all future releases.</li>
  <li>Get the UCA in rule format, then check that if we tailor for those rules, we get the same result.</li>
</ol>
<h2><a name="Modifications">Modifications</a></h2>
<h3>Version 16</h3>
<ul>
  <li>General cleanup, reorganization.</li>
  <li>16b: added <a href="#Merge_Comparison_API">Merge Comparison API</a></li>
  <li>16c: added or fixed
    <ul>
      <li><a href="#Magic_Bytes">Appendix 5: Magic Bytes</a> (and related values in the text)</li>
      <li><a href="#Testing">Appendix 6: Testing</a></li>
      <li><a href="#Semantic_Changes">Semantic Changes</a></li>
      <li>&quot; [before n]&quot; rule syntax</li>
    </ul>
  </li>
  <li>16d: added or fixed
    <ul>
      <li><a href="#Normal_and_Continuation_Format">Normal and Continuation Format</a></li>
      <li>Distinguished CJK implicits from other implicits</li>
      <li>Other misc. changes</li>
      <li>Fixed contraction table to correspond to optimizations for discontiguous contraction</li>
      <li>Added primary compression and other optimizations added in 1.8.1.</li>
    </ul>
  </li>
</ul>
<h3>Version 15</h3>
<ul>
  <li>Deleted Long Primary. In practice, we found it too much trouble.</li>
  <li>Modified <a href="#Quarternary">Quarternary</a>. Note that Variable Top may be 2 bytes.</li>
  <li><a href="#Appending_Levels">Appending Levels</a> more accurately reflects what we do.</li>
  <li>Added <a href="#String_Compare">String Compare</a>.</li>
  <li>Amended <a href="#Details_on_Generation">Details on Generation</a>: it needed ranges Low and High, and better description of computing intervening 
    weights. In particular:
    <ul>
      <li><a href="#Assigning_CEs">Assigning CEs</a></li>
      <li>
        <p align="left"><a href="#Intermediate_CEs">Intermediate CEs</a></li>
    </ul>
  </li>
  <li>Added <a href="#Discontiguous_Contractions">Discontiguous Contractions</a></li>
  <li>Slight changes to <a href="#Versioning">Versioning</a></li>
  <li>Added &quot;ch&quot; discussion to <a href="#Case_Handling">Case Handling</a></li>
  <li>Version c:
    <ul>
      <li>Added sections: <a href="#Hangul_Implicit_CEs">Hangul_Implicit_CEs</a>, <a href="#Hangul_Building">Hangul_Building</a></li>
    </ul>
  </li>
  <li>Version d:
    <ul>
      <li>added <a href="#Normalization">Normalization</a></li>
      <li>added <a href="#Assigning_Expansions">Assigning Expansions</a></li>
    </ul>
  </li>
  <li>Version e:
    <ul>
      <li>Fleshed out <a href="#CheckFCD">CheckFCD</a> a bit more, added some cross references.</li>
    </ul>
  </li>
  <li>Version g
    <ul>
      <li>Added <a href="#Loose_Match_Utility">Loose Match Utility</a> (post 1.8)</li>
      <li>Updated <a href="#UCA_Processing">UCA Processing</a></li>
      <li>Added rules file to <a href="#Data_Tables">Data Tables</a></li>
    </ul>
  </li>
  <li>Version h
    <ul>
      <li>Rename for clarity, Contraction Complication and Case Level to <a href="#Discontiguous_Contractions">Discontiguous Contractions</a> and <a
        href="#Case_Handling">Case Handling</a>.</li>
      <li>Moved <a href="#Japanese_Collation_Tailoring">Japanese Collation Tailoring</a></li>
      <li>Expanded <a href="#Case_Handling">Case Handling</a> to talk about the case level.</li>
      <li>Added <a href="#UCA_Case_Bit">UCA Case Bit</a> and <a href="#Tailoring_Case_Bit">Tailoring Case Bit</a> to explain how the bit is generated in UCA and 
        Tailoring tables.</li>
      <li>Expanded section on <a href="#Backup">Backup</a>.</li>
      <li><a href="#Discontiguous_Contractions">Discontiguous Contractions</a>, <a href="#Multiple_Case_Bits">Multiple Case Bits</a> and <a href="#Appendix_2">Compressed 
        Primaries</a> are post 1.8 features.</li>
    </ul>
  </li>
  <li>Minor other editing.</li>
</ul>
<h3>Version 14</h3>
<ul>
  <li>Tailoring syntax for changing the variable range was missing, so that was added.</li>
  <li>When going backwards, expansion CEs must be reversed, with continuation CEs handled specially.</li>
  <li>Added subtable counts to header. Made clear that tables are not in predetermined order. Changed Trie to Main, since there may be multiple Trie tables.</li>
  <li>Made more clear that offset in contraction UChar table is a delta</li>
  <li>Added [last] syntax for Tailoring.</li>
  <li>Modified the bit distribution in <a href="#CollationElementFormat">CollationElements</a></li>
  <li>Modified the generation of <a href="#Implicit_CEs">Implicit_CEs</a></li>
  <li>Added <a href="#Details_on_Generation">Details_on_Generation</a></li>
  <li>Added details on <a href="#Compression">Compression</a></li>
  <li>Added <a href="#Issues">Issues</a> section. This needs to be reviewed and discussed!</li>
</ul>
<hr>
<p align="center"><i>Copyright ยฉ 2000-2001, IBM Corp. All Rights Reserved.</i></p>

</body>

</html>
