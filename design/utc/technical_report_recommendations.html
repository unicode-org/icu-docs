<html>

<head>
<meta http-equiv="Content-Language" content="en-us">
<meta name="GENERATOR" content="Microsoft FrontPage 5.0">
<meta name="ProgId" content="FrontPage.Editor.Document">
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<title>Technical Report Changes</title>
<style>
<!--
p            { margin-left: 2em }
li	{margin-top:6pt; margin-bottom:6pt}
-->
</style>
</head>

<body>

<h1>Technical Report Recommendations</h1>
<p>Mark Davis, 2004-07-23</p>
<p>Latest Version:
<a href="http://oss.software.ibm.com/cvs/icu/~checkout~/icuhtml/design/utc/technical_report_recommendations.html">
http://oss.software.ibm.com/cvs/icu/~checkout~/icuhtml/design/utc/technical_report_recommendations.html</a>
</p>
<p>The following are recommended changes for certain technical reports in the U4.1 timeframe. The 
proposal is to authorize the posting of Proposed Updates incorporating the following changes between 
now and November, to allow more time for public feedback.</p>
<h2>UAX #15 <a href="http://www.unicode.org/reports/tr15/">Unicode Normalization Forms</a></h2>
<p>Needs updating for U4.1 to incorporate the corrigendum, moving identifier section to TR31 (a stub 
will be left to point to it), plus editing to have definitions more consistent with #23 and #30. The 
following have been reported as problems; they need to be reviewed and fixed if so.</p>
<ol>
  <li>&quot;(In NFKC and NFKD, a K is used to stand for compatibility to avoid confusion with the C 
  standing for canonical.)&quot;<br>
  Here, 'canonical' should be changed to 'composition', because that's what the C in NFC and NFKC 
  stands for. </li>
  <li>Change the contents listing to the same style as in the template. </li>
  <li>Replace the two PPT slides by tables. On some of my screens the anti-aliasing makes them 
  completely unreadable. </li>
  <li>Change the notation section into a table, so that the notation being described is in the left 
  hand column. That makes it much easier to locate something. </li>
  <li>Consider italicizing variables to set them off from text. </li>
  <li>The sentence &quot;This can be written as P in X=Q in Y.&quot; is really hard to read. consider putting 
  the formula on a line by itself. </li>
  <li>Annex 13 should not be an annex. The definition of respcting Can, Equiv. should be a formal 
  definition, not hidden in the text. </li>
  <li>There's a problem with the opening paragraph in Annex13. As defined, canonical equivalence 
  *only* applies to strings. Therefore your distinction between preserving and respecting makes no 
  sense (as worded).
  <p>This section describes the relationship of normalization to respecting (or preserving) 
  canonical equivalence. A process (or function) respects canonical equivalence when canonical 
  equivalent inputs always produce canonically equivalent outputs. For functions that map strings to 
  strings, this is often called preserving canonical equivalence. There are a number of important 
  aspects to this concept: </li>
  <li>&quot;The canonically equivalent inputs or outputs are not just limited to strings, but are also 
  relevant to the offsets within strings, since those play a fundamental role in Unicode string 
  processing.&quot; is also a pocket definition, this time of 'canonically equivalent offset'. Should be 
  a formal definition.</li>
</ol>
<h2>UAX #29 <a href="http://www.unicode.org/reports/tr29/">Text Boundaries </a>(UAX #14
<a href="http://www.unicode.org/reports/tr14/">Line Breaking Properties</a>)</h2>
<p>We should modify word selection so that it has the same 'escape hatch' as line break, for 
Thai/Lao. It would thus be parallel to Line Break's LB 1.</p>
<blockquote>
  <p><i>LB 1&nbsp; Assign a line breaking class to each character of the input. Resolve
  <a class="charclass" href="#AI">AI</a>, <a class="charclass" href="#CB">CB</a>,
  <a class="charclass" href="#SA">SA</a>, <a class="charclass" href="#SG">SG</a>,
  <a class="charclass" href="#XX">XX</a> into other line breaking classes depending on criteria 
  outside the scope of this algorithm.</i></p>
</blockquote>
<p>In a related matter, we need to incorporate the LineBreak corrigendum into LineBreak, and modify 
the TR to remove LB 7a.</p>
<blockquote>
  <p><i>LB 7a&nbsp; In all of the following rules, if a space is the base character for a combining 
  mark, the space is changed to type <a class="charclass" href="#ID">ID</a>. In other words, break 
  before <a class="charclass" href="#SP">SP</a> <a class="charclass" href="#CM">CM*</a> in the same 
  cases as one would break before an <a class="charclass" href="#ID">ID</a>.</i></p>
</blockquote>
<p>And document that NBSP is the preferred base character for showing combining marks in isolation.</p>
<p>As it turns out, the rule LB 6 </p>
<blockquote>
  <p><i>LB 6&nbsp; Don’t break a Korean Syllable Block, and treat it as a single unit of the same LB 
  class as a Hangul Syllable in all the following rules</i></p>
</blockquote>
<p align="center">Treat a Korean Syllable block as if it were ID</p>
<p>only has an effect in 5 rules:</p>
<p align="center">ID × IN</p>
<p align="center">ID × PO</p>
<p align="center">PR × ID</p>
<p align="center">ALL ÷</p>
<p align="center">÷ ALL</p>
<p>Such &quot;treat as&quot; rules are difficult for regular expression implementations <i>and</i> for pair 
tables. They complicate regular expressions because they affect every instance where any characters 
could match; they complicate pair tables since they require prehandling in code, outside of the pair 
table.</p>
<p>We can safely replace LB 6 by adding the following rules. (And should do so). They can go 
anyplace before the ALL rules, and can be put in logical locations. The first three rules correspond 
to the first three above; the last three disallow breaking in the middle of a Hangul Syllable (as 
described in Chapter 3).</p>
<p align="center">L | V | T | LV | LVT × IN</p>
<p align="center">L | V | T | LV | LVT&nbsp; × PO</p>
<p align="center">PR × L | V | T | LV | LVT</p>
<p align="center">L&nbsp; × L | V | LV | LVT</p>
<p align="center">V | LV × V | T</p>
<p align="center">T | LVT × T</p>
<h2>UTS #18 <a href="http://www.unicode.org/reports/tr18/">Unicode Regular Expressions</a></h2>
<p>Needs updating for U4.1 for to account for changes in foldings, properties, names, scripts. Other 
items:</p>
<ol>
  <li>Also add descriptions of the following so that they can be referenced in other UTRs, 
  especially #30.<ol>
    <li>grouping syntax, e.g. (ab*) cd</li>
    <li>references, ie $0,$1-$9 in Perl, used in the replacement part to refer to a group</li>
    <li>variables, ie defining $xyz = [[:greek:]&amp;[:lowercase:]], then using it in multiple regular 
    expressions</li>
  </ol>
  </li>
  <li>Since any character could occur as a literal in a regular expression, when regular expression 
  syntax is embedded within other syntax it can be difficult to determine where the end of the regex 
  expression is. Add a section to Level 2 describing the issue.</li>
  <li>Consider adding a conformance clause for
  <a href="http://www.unicode.org/reports/tr18/#Compatibility_Properties">
  http://www.unicode.org/reports/tr18/#Compatibility_Properties</a>, so that if people want to claim 
  conformance to them they can. Also consider having a second column that follows the POSIX 
  partitioning constraints.</li>
  <li>principle use =&gt; principal use</li>
  <li>\p{gc=Decimal_Number} ...<br>
  &quot;Non-decimal numbers (like Roman numerals) are normally excluded. In U4.0+, this is the same as gc 
  = Decimal_Number (Nd).&quot; =&gt;<br>
  &quot;Non-decimal numbers (like Roman numerals) are normally excluded. In U4.0 and U4.1+, this is the 
  same as Numeric_Type = Decimal (nt=De).&quot;<br>
  [Since we slipped up in 4.0.1, and Nd was wrong.]</li>
  <li>Note: ZWSP, while a Z character, is for line break control and should not be included.<br>
  [Remove: It recently (U4.0.1) became a Cf.]</li>
</ol>
<h2>UTS #23 <a href="http://www.unicode.org/reports/tr23/">Character Properties</a></h2>
<p>I have scanned through a number of the TRs, and found other useful definitions that we should 
centralize so that they can be used consistently. Asmus may have already incorporated some these 
into his draft for the meeting; if so, skip over those that are.</p>
<ol>
  <li style="margin-top: 6pt; margin-bottom: 6pt">By convention, toX(a) is notation used for a 
  function that produces a result of the form X. Thus toLowercase(a) produces a lowercase form from 
  a. There is a related function isX(a), coordinated with toX, whereby isX(a) is true if and only if 
  toX(a) = a.<ul>
    <li style="margin-top: 6pt; margin-bottom: 6pt">It is important to distinguish being in a format 
    from converting to that format, because mixing them up is fairly common and leads to 
    misunderstandings.</li>
    <li style="margin-top: 6pt; margin-bottom: 6pt">Used in UTS #15, Chapter 3.</li>
  </ul>
  </li>
  <li style="margin-top: 6pt; margin-bottom: 6pt">Define the <i>closure</i> of a string S under a 
  folding F to be the set of all strings that fold to it. Eg,<ul>
    <li>closure('aa', toLowercase) =&gt; {'aa', 'Aa', 'aA', 'AA'}</li>
    <li>closure('&#974;', toNFC) =&gt; {<font face="Arial Unicode MS">'&#974;', '&#969;&#833;', '&#969;&#769;'</font>}<ul>
      <li>The difference in the latter two is between <a href="?ch=0341">U+0341</a> COMBINING ACUTE 
      TONE MARK and <a href="?ch=0301">U+0301</a> COMBINING ACUTE ACCENT</li>
    </ul>
    </li>
  </ul>
  </li>
  <li style="margin-top: 6pt; margin-bottom: 6pt">Define the <i>closure</i> of a set of strings SS 
  under a set of foldings SF to be the union of the closures of the strings in SS. Eg for the 
  toLowercase function,
  <ul>
    <li>closure({'aa', 'AA', '<font SIZE="3">ß</font>'}, {toLowercase, toUppercase, toTitlecase}) =&gt; 
    {'aa', 'Aa', 'aA', 'AA', '<font SIZE="3">ß</font>',&nbsp; 'ss', 'sS', 'SS', 'Ss'}</li>
    <li>used in case folding</li>
  </ul>
  </li>
  <li style="margin-top: 6pt; margin-bottom: 6pt">Define the <i>fold of a set</i> of strings SS to 
  be the union of the set of foldings of the elements of SS. E.g.
  <ol>
    <li>toLowercase({'aa', 'Aa', 'aA', 'AA', 'b',&nbsp; 'B'}) =&gt; {'aa', 'b'}</li>
  </ol>
  </li>
  <li style="margin-top: 6pt; margin-bottom: 6pt">Define what it is to <i>preserve</i> a relation. A 
  transform F preserves a relation R, when R(a,b) implies R(F(a), F(b))<ul>
    <li style="margin-top: 6pt; margin-bottom: 6pt">Thus a transform preserves a boolean function 
    isX, when isX(a) =&gt; isX(F(a))</li>
    <li style="margin-top: 6pt; margin-bottom: 6pt">This is used in UTS #15 and other places,
    <ul>
      <li style="margin-top: 6pt; margin-bottom: 6pt">e.g. toNFC preserves canonical equivalence, 
      because if isCE(a,b) then isCE( NFC(a), toNFC(b) )</li>
      <li style="margin-top: 6pt; margin-bottom: 6pt">a function preserves a normalization form NFC:&nbsp; 
      isNFC(a) implies that isNFC(F(a))</li>
    </ul>
    </li>
    <li>When F preserves R, this can also be expresses as saying R <i>is closed under</i> F. For 
    example, you can say that programming identifiers are closed under NFC, meaning <code>
    isIdentifier(S)</code> implies <code>isIdentifier(toNFC(S))</code></li>
  </ul>
  </li>
  <li style="margin-top: 6pt; margin-bottom: 6pt">Explain how you can change a transform F so that 
  it preserves a relation. Use the example of normalization.<ol>
    <li style="margin-top: 6pt; margin-bottom: 6pt">In the general case, the new transform is 
    defined as F'(s) = toNFC(F(toNFC(s))</li>
    <li style="margin-top: 6pt; margin-bottom: 6pt">If F preserves canonical equivalence, then it 
    can avoid a step: F'(s) = toNFC(F(x))</li>
  </ol>
  </li>
  <li style="margin-top: 6pt; margin-bottom: 6pt">Also, explain that from a partition one can 
  generate a folding, by generating a function that picks one element of each partition to be the 
  element that all and only the others in that partition fold to. That is what is done in generating 
  CaseFolding, for example.</li>
  <li>Add a section after Canonical Equivalence (in Asmus's current draft) called <b>Normalized 
  Input</b><p>If the input is guaranteed to be in NFD, then Step 1 is simpler. Additional rules do 
  not have to be generated; instead, the matching part of the rule just needs to be transformed into 
  NFD. Thus instead of generating new rules, one simply replaces a rule like: </p>
  <p>&lt;A-acute&gt; &lt;dot_under&gt; -&gt; Z </p>
  <p>with: </p>
  <p>A &lt;dot_under&gt; &lt;acute&gt; -&gt; Z </p>
  <p>Step 2 will be the same; however, it will need to be applied to fewer cases, since fewer rules 
  will result from Step 1. </li>
  <li>Add a section after Canonical Equivalence (in Asmus's current draft) called <b>Normalized 
  Output</b><p>The above two steps ensure that the folding preserves canonical equivalence. However, 
  they do not guarantee that the folding preserves normalization. If normalization is required, then 
  it must be applied as an additional step. This is typically an issue whenever the result of a rule 
  contains combining marks. If normalization is to be applied after the each rule is applied, there 
  are implementation techniques described in [Normalization] for ways to optimize this process. 
  However, if there are any sizable number of changes, it is more efficient -- and certainly simpler 
  -- to simply normalize the entire text once all of the rules have been applied. </li>
</ol>
<h2>UTR #30 <a href="http://www.unicode.org/reports/tr30/">Character Foldings</a></h2>
<p>The DiacriticFolding would be better expressed as an AncillaryDecompositions.txt, removing all 
the mappings that are merely duplicates of the canonical decompositions, and retaining only mappings 
like:</p>
<p>00D8; 004F <a href="?ch=0335#here">0335</a> # Ø LATIN CAPITAL LETTER O WITH STROKE</p>
<p>This reduces duplication of data, and retains the data in a form that is most useful. If someone 
wants to strip the combining marks, that is easy to do afterwards; but you can't add them if they 
are not in the data in the first place. The extra data is particularly useful for detecting 
spoofing: see my document on Unicode Security Considerations.</p>
<h2>Related Items</h2>
<p>These are copied from mail on property topics:</p>
<ul>
  <li>U4.0.1 changes U+002F Solidus from ES to CS but leaves U+FF0F Fullwidth Solidus at ES. U+FF0F 
  should probably have the same bidi class as its regular sibling.</li>
  <li>There's another misclassification, this one for a relatively new character that we didn't 
  think through correctly when adding: NNBSP needs to be changed from WS to CS (in analogy to NBSP). 
  The reason is that in all scripts but Mongolian it acts like NBSP except for its width. In 
  Mongolian it may be recognized in shaping (details to be forthcoming).</li>
  <li>We should also address explicitly the situation of &lt;WJ, SP, WJ&gt; we say this is equivalent to 
  NBSP. Clearly, that's not true for its bidi properties. We need to check the text to make sure 
  that discrepancy is noted, for example by stating on page 387 &quot;for purposes of line breaking&quot; or 
  some such qualifier, and noting: &quot;However, NBSP has a specific bidirectional behavior, which is 
  different from this sequence (see UAX#9).&quot;<p>&nbsp;</li>
</ul>
<p>&nbsp;</p>

</body>

</html>
